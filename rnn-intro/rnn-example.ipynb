{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of an RNN\n",
    "\n",
    "We construct a simple RNN to generate text from a work of Nietsche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup libraries and functions.\n",
    "\n",
    "We start by importing various libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots displayed inline in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Make help libraries available\n",
    "import sys\n",
    "\n",
    "sys.path.append('D:/anlaursen/libraries')\n",
    "\n",
    "# Set visible devices, so as to just use a single GPU.\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from numpy.random import choice\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, TimeDistributed, Activation\n",
    "from keras.layers.core import Dropout, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import get_file\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Nietsche data and save it as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt',\n",
    "                origin = \"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read().lower()\n",
    "\n",
    "print('\\ncorpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider an example. We see that the text is very convoluted (haha), which in this case make it easier for a model, as it will be hard for us humans to undertand wether something is true Nietsche tect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " all existence, in an impending day of\n",
      "judgment. in the last rays of the setting sun of the ancient world,\n",
      "which fell upon the christian peoples, the shadowy form of the saint\n",
      "attained enormous proportions--to such enormous proportions, indeed,\n",
      "that down even to our own age, which no longer believes in god, there\n",
      "are thinkers who believe in the saints.\n",
      "\n",
      "\n",
      "144\n",
      "\n",
      "it stands to reason that this sketch of the saint, made upon the model\n",
      "of the whole species, can be confronted with many opposing sketches that\n",
      "would create a more agreeable impression. there are certain exceptions\n",
      "among the species who distinguish themselves either by especial\n",
      "gentleness or especial humanity, and perhaps by the strength of their\n",
      "own personality. others are in the highest degree fascinating because\n",
      "certain of their delusions shed a particular glow over their whole\n",
      "being, as is the case with the founder of christianity who took himself\n",
      "for the only begotten son of god and hence felt himself sinless; so that\n",
      "through his imagination--that should not be too harshly judged since the\n",
      "whole of antiquity swarmed with sons of god--he attained the same goal,\n",
      "the sense of complete sinlessness, complete irresponsibility, that can\n",
      "now be attained by every individual through science.--in the same manner\n",
      "i have viewed the saints of india who occupy an intermediate station\n",
      "between the christian saints and the greek philosophers and hence are\n",
      "not to be regarded as a pure type. knowledge and science--as far as they\n",
      "existed--and superiority to the rest of mankind by logical discipline\n",
      "and training of the intellectual powers were insisted upon by the\n",
      "buddhists as essential to sanctity, just as they were denounced by the\n",
      "christian world as the indications of sinfulness.\n"
     ]
    }
   ],
   "source": [
    "print(text[-1750:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then make a list of all charcters used in the text. And determine the size of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 60\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars) + 1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's useful to have a zero value in the dataset, e.g. for padding, so we add that. And consider the output (-6 removes forreign utf-8 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?[]_abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then make a dict for characters and for indices. So each character gets mapped to an indecy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convert the text using these indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the first ten characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43, 45, 32, 33, 28, 30, 32, 1, 1, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corresponding to (Note the annoying line feeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preface\\n\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then construct running sentences where each sentence in a pair is one character aahead of the other sentence in the pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 600862\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(idx) - maxlen + 1):\n",
    "    sentences.append(idx[i: i + maxlen])\n",
    "    next_chars.append(idx[i+1: i + maxlen + 1])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then construct an array of sentences and the same sentences moved one character forward. Essentially a training set and a label set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can validate that the two arrays have the same shape. That is 600860 sentences of 40 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600860, 40), (600860, 40))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.shape, next_chars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We speccify the number of factors to use in our embedding of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An we can then contruct out RNN, specifically a long-short term memory recurrent neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length = maxlen),\n",
    "        LSTM(512,\n",
    "             input_shape = (None, n_fac),\n",
    "             return_sequences = True,\n",
    "             recurrent_dropout = 0.2,\n",
    "             dropout = 0.2,\n",
    "             # Implementation: One of {0, 1, or 2}. If set to 0, the RNN will use an\n",
    "             # implementation that uses fewer, larger matrix products, thus running \n",
    "             # faster on CPU but consuming more memory. If set to 1, the RNN will use \n",
    "             # more matrix products, but smaller ones, thus running slower (may \n",
    "             # actually be faster on GPU) while consuming less memory. If set to 2 \n",
    "             # (LSTM/GRU only), the RNN will combine the input gate, the forget gate \n",
    "             # and the output gate into a single matrix, enabling more time-efficient \n",
    "             # parallelization on the GPU.\n",
    "             implementation = 2),\n",
    "        Dropout(0.2),\n",
    "        LSTM(512,\n",
    "             return_sequences = True,\n",
    "             recurrent_dropout = 0.2,\n",
    "             dropout = 0.2,\n",
    "             implementation = 2),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the LSTM RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function such as to print sample predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example():\n",
    "    \n",
    "    # WE have to see the model, so we pick something, that sounds Nietsche like.\n",
    "    seed_string = \"ethics is a basic foundation of all that\"\n",
    "    \n",
    "    for i in range(320):\n",
    "        x = np.array([char_indices[c] for c in seed_string[-40:]])[np.newaxis, :]\n",
    "        preds = model.predict(x, verbose = 0)[0][-1]\n",
    "        preds = preds / np.sum(preds)\n",
    "        next_char = choice(chars, p = preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    print(seed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40, 24)            1440      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 40, 512)           1099776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 40, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40, 512)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 40, 60)            30780     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 40, 60)            0         \n",
      "=================================================================\n",
      "Total params: 3,231,196\n",
      "Trainable params: 3,231,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train the model for a single epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "600860/600860 [==============================] - 1302s - loss: 1.5140  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a3e6944a8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars, -1), batch_size = 64, epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And print the prediction. After the first epoch we see that sentence and word structure is starting to form, but the output is rather terrible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that for his basis and nothing! so around\n",
      "coor. from nature which is\n",
      "in called \"strength,\" we have reac and sevented supposing a master than the dome conscience likewise a more\n",
      "repugiated, the -orrance and dislike, and always, prosure of impossible quite his\n",
      "head that ruling civilization but he must\n",
      "be essentially explaine\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we run for an epoch more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "600860/600860 [==============================] - 1282s - loss: 1.2868  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a3e6c3d30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars, -1), batch_size = 64, epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's actually starting to construct words, sentences and using punctuation. But it is still rather meaningsless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that account for a\n",
      "distance, because man who is\n",
      "essential to generation, that is to say, a \"science more to slead,\" with regard to friends this\n",
      "formerly disguise, and so luther at all, which an eternal latter--delusions of \"man\" a sort of raised\n",
      "man: this church has been interesting fly.--young soul is not only the worst r\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we decrease the learning rate and run for another epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "600860/600860 [==============================] - 1299s - loss: 1.2526  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a496e3940>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "\n",
    "model.fit(sentences, np.expand_dims(next_chars, -1), batch_size = 64, epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're starting to get somewhere. We have somthing that can be read and is actual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that arises\n",
      "itself out, wull to develop the \"pmantom of\n",
      "our \"noble sinkulness\" and instincts. (but what happens in the intercourse that he does not possess of the old fellow creature, but thus may be blended that religion and dangerous and enchanted and spirits and also are more refined france of\n",
      "evil things, for instance,\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decrease the learning rate and run another epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "600860/600860 [==============================] - 1292s - loss: 1.2336  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a496e3fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.0001\n",
    "\n",
    "model.fit(sentences, np.expand_dims(next_chars, -1), batch_size = 64, epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are starting to get chapter marks and paragraph marks as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that? only these\n",
      "most successful sentiments so hardly\n",
      "interpreted about him as the reason also so highly disclosed the\n",
      "due to be\n",
      "sure, only in our\n",
      "issinctions of depth! the man should roluse it in order to have really considered the part of religious havoured, in\n",
      "the author to make\n",
      "responsibility and north in religion and \n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we save the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%mkdir models\n",
    "model.save_weights('models/char_rnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And decrease the learning rate even more and run for another epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "    64/600860 [..............................] - ETA: 1549s - loss: 1.2666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600860/600860 [==============================] - 1299s - loss: 1.2190  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a496f93c8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars, -1), batch_size = 64, epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are getting something quite nietsche like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that are blame they\n",
      "rank and at the same time in its ultruth; and\n",
      "out require their regularity\n",
      "of the occasions).--he writes to himself about conquering fundamental boldness\n",
      "of his learned men, if a philosopher, to possession to\n",
      "reuden, is such as conduct. but if it were that\n",
      "it is not a delicate, to look from\n",
      "which the ri\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a final epoch and consider two examples. Very Nietsche like now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "600860/600860 [==============================] - 1294s - loss: 1.2015  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a496f9160>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars, -1), batch_size = 64, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that an act of a\n",
      "danger in a finer sensation of the condemned man, humanity has given before the \"happiness\" extend)\n",
      "could not nover indirectly be greater into\n",
      "aul events can be frigntful, although he will come to him and agony the uplers of system of\n",
      "tragedy--which a means, only confounds a second, moral,\n",
      "sacrifice, goal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that is transfigurated;--and potent woman renounces over-rich\n",
      "more the striving for restraint through everything draws at\n",
      "the whole spirit man grows\n",
      "pleasure and deny myn, divined whatever, around\n",
      "whatever they should have honoured by his nature.\n",
      "\n",
      "\n",
      "123\n",
      "\n",
      "=stupidity--the called \"will,\" they wish\n",
      "to be slain own experiences w\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it can also generate proper chapter marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/char_rnn.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
