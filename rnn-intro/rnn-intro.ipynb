{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to RNN\n",
    "\n",
    "We use Nietsche text data to showcase how Recurrant neural networks work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup libraries and functions.\n",
    "\n",
    "We start by importing various libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plots displayed inline in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Make help libraries available\n",
    "import sys\n",
    "\n",
    "sys.path.append('D:/anlaursen/libraries')\n",
    "\n",
    "# Set visible devices, so as to just use a single GPU.\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "import math\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Input, BatchNormalization\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import get_file, to_categorical\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "from numpy.random import normal\n",
    "from itertools import chain\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data\n",
    "\n",
    "We're going to download the collected works of Nietzsche to use as our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt',\n",
    "                origin = \"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider an example. We see that the text is very convoluted (haha)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " all existence, in an impending day of\n",
      "judgment. In the last rays of the setting sun of the ancient world,\n",
      "which fell upon the christian peoples, the shadowy form of the saint\n",
      "attained enormous proportions--to such enormous proportions, indeed,\n",
      "that down even to our own age, which no longer believes in god, there\n",
      "are thinkers who believe in the saints.\n",
      "\n",
      "\n",
      "144\n",
      "\n",
      "It stands to reason that this sketch of the saint, made upon the model\n",
      "of the whole species, can be confronted with many opposing sketches that\n",
      "would create a more agreeable impression. There are certain exceptions\n",
      "among the species who distinguish themselves either by especial\n",
      "gentleness or especial humanity, and perhaps by the strength of their\n",
      "own personality. Others are in the highest degree fascinating because\n",
      "certain of their delusions shed a particular glow over their whole\n",
      "being, as is the case with the founder of christianity who took himself\n",
      "for the only begotten son of God and hence felt himself sinless; so that\n",
      "through his imagination--that should not be too harshly judged since the\n",
      "whole of antiquity swarmed with sons of god--he attained the same goal,\n",
      "the sense of complete sinlessness, complete irresponsibility, that can\n",
      "now be attained by every individual through science.--In the same manner\n",
      "I have viewed the saints of India who occupy an intermediate station\n",
      "between the christian saints and the Greek philosophers and hence are\n",
      "not to be regarded as a pure type. Knowledge and science--as far as they\n",
      "existed--and superiority to the rest of mankind by logical discipline\n",
      "and training of the intellectual powers were insisted upon by the\n",
      "Buddhists as essential to sanctity, just as they were denounced by the\n",
      "christian world as the indications of sinfulness.\n"
     ]
    }
   ],
   "source": [
    "print(text[-1750:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then make a list of all charcters used in the text. And determine the size of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 86\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's useful to have a zero value in the dataset, e.g. for padding, so we add that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then make a dict for characters and for indices. So each character gets mapped to an indecy and back again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idx will be the data we use from now own - it simply converts all the characters to their index (based on the mapping above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the first ten characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corresponding to (Note the annoying line feeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 character unrolled model\n",
    "\n",
    "We make a model to predict the fourth character based on the previous three caracters. We do this using the standard functional API in Keras. So we showcase how to build a RNN like model the hard way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs\n",
    "\n",
    "Create a list of every 4th character, starting at the 0th, 1st, 2nd, then 3rd characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs = 3\n",
    "c1_dat = [idx[i] for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c2_dat = [idx[i + 1] for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c3_dat = [idx[i + 2] for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c4_dat = [idx[i + 3] for i in range(0, len(idx) - 1 - cs, cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert to numpy arrays by stacking, and thus get the inputs to out model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat[:-2])\n",
    "x2 = np.stack(c2_dat[:-2])\n",
    "x3 = np.stack(c3_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same to get our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c4_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can consider the first four inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40, 30, 29,  1]), array([42, 25,  1, 43]), array([29, 27,  1, 45]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 29,  1, 40])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the shame. We have 1 dimensional arrays of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200297,), (200297,), (200297,), (200297,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, x2.shape, x3.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then state the number of latent factors to create in the embedding (i.e. the size of the embedding matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create inputs and embedding outputs for each of our three character inputs. (Note each use the same, so we create it as a function returning the input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape = (1, ), dtype = 'int64', name = name)\n",
    "    emb = Embedding(n_in, n_out, input_length = 1)(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input and output for each three character input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_in, c1 = embedding_input('c1', vocab_size, n_fac)\n",
    "c2_in, c2 = embedding_input('c2', vocab_size, n_fac)\n",
    "c3_in, c3 = embedding_input('c3', vocab_size, n_fac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train unrolled model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a size for our hidden statem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the layer operation from input to hidden (the 'green arrow' from our diagram). Note that it is not activated yet, we have yet to apply a layer into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation = 'relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first hidden activation is simply this function applied to the result of the embedding of the first character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_hidden = dense_in(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the layer operation from hidden to hidden, (the 'orange arrow' from our diagram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_hidden = Dense(n_hidden, activation = 'tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second and third hidden activations sum up the previous hidden state (after applying dense_hidden) to the new input state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c2_dense = dense_in(c2)\n",
    "hidden_2 = dense_hidden(c1_hidden)\n",
    "c2_hidden = add([c2_dense, hidden_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c3_dense = dense_in(c3)\n",
    "hidden_3 = dense_hidden(c2_hidden)\n",
    "c3_hidden = add([c3_dense, hidden_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the layer operation from hidden to output, (the 'blue arrow' from our diagram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_out = Dense(vocab_size, activation = 'softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third hidden state is the input to our output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c4_out = dense_out(c3_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define our model using the three inputs (which we defined above), and the output from the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "c3 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c2 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c1 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 1, 42)         3612        c3[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 1, 42)         3612        c2[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 1, 42)         3612        c1[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 42)            0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 42)            0           embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 42)            0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 256)           11008       flatten_1[0][0]                  \n",
      "                                                                   flatten_2[0][0]                  \n",
      "                                                                   flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           65792       dense_1[0][0]                    \n",
      "                                                                   add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 256)           0           dense_1[1][0]                    \n",
      "                                                                   dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 256)           0           dense_1[2][0]                    \n",
      "                                                                   dense_2[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 86)            22102       add_2[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 109,738\n",
      "Trainable params: 109,738\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([c1_in, c2_in, c3_in], c4_out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200297/200297 [==============================] - 21s - loss: 2.4031    \n",
      "Epoch 2/10\n",
      "200297/200297 [==============================] - 18s - loss: 2.2693    \n",
      "Epoch 3/10\n",
      "200297/200297 [==============================] - 19s - loss: 2.2229    \n",
      "Epoch 4/10\n",
      "200297/200297 [==============================] - 18s - loss: 2.1773    \n",
      "Epoch 5/10\n",
      "200297/200297 [==============================] - 18s - loss: 2.1415    \n",
      "Epoch 6/10\n",
      "200297/200297 [==============================] - 18s - loss: 2.1169    \n",
      "Epoch 7/10\n",
      "200297/200297 [==============================] - 19s - loss: 2.0999    \n",
      "Epoch 8/10\n",
      "200297/200297 [==============================] - 19s - loss: 2.0887    \n",
      "Epoch 9/10\n",
      "200297/200297 [==============================] - 18s - loss: 2.0800    \n",
      "Epoch 10/10\n",
      "200297/200297 [==============================] - 19s - loss: 2.0738    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f08798978>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size = 64, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that returns the predictions for a given input sequence of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict(arrs)\n",
    "    i = np.argmax(p)\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then try different inputs in order to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('phi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' an')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to work great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First RNN using low level parts of Keras API\n",
    "\n",
    "We create a sample unrolled RNN the hard way using the functional API of Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input\n",
    "\n",
    "This is the size of our unrolled RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of 0 through 7, create a list of every 8th character with that starting point. These will be the 8 inputs to out model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i + n] for i in range(0, len(idx) - 1 - cs, cs)] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a list of the next character in each of these series. This will be the labels for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [idx[i + cs] for i in range(0, len(idx) - 1 - cs, cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create the input as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = [np.stack(c[:-2]) for c in c_in_dat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have an array of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, (75110,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs), xs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is a simple one dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75110,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each column below is one series of 8 characters from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([40,  1, 33,  2, 72, 67, 73,  2]),\n",
       " array([42,  1, 38, 44,  2,  9, 61, 73]),\n",
       " array([29, 43, 31, 71, 54,  9, 58, 61]),\n",
       " array([30, 45,  2, 74,  2, 76, 67, 58]),\n",
       " array([25, 40, 73, 73, 76, 61, 24, 71]),\n",
       " array([27, 40, 61, 61, 68, 54,  2, 58]),\n",
       " array([29, 39, 54,  2, 66, 73, 33,  2]),\n",
       " array([ 1, 43, 73, 62, 54,  2, 72, 67])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[xs[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and this is the next character after each sequence. Which as we can see is also the first character of each sequence after the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 33,  2, 72, 67, 73,  2, 68])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then state the number of latent factors to create in the embedding (i.e. the size of the embedding matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining the embedding input layers again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1, ), dtype = 'int64', name = name + '_in')\n",
    "    emb = Embedding(n_in, n_out, input_length = 1, name = name + '_emb')(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create the embeddings for each eight characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_ins = [embedding_input('c' + str(n), vocab_size, n_fac) for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define our dense layers. That is the input, hidden and output dense layers. Note again that these are not activated before we pass something to them.\n",
    "Also note that we initialise the weights using the identity matrix rather than eg. Xavier initialisation. That way we start out by having the hidden state stay the same for each layer of the RNN. That makes intuitive sense, as absent of any new information, we would imagine each layer to be the same. It also makes sense from an empirical point of view, as demonstrated by [this paper](https://arxiv.org/pdf/1504.00941.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "\n",
    "dense_in = Dense(n_hidden, activation = 'relu')\n",
    "dense_hidden = Dense(n_hidden, activation = 'relu', kernel_initializer = 'identity')\n",
    "dense_out = Dense(vocab_size, activation = 'softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first character of each sequence goes through dense_in(), to create our first hidden activations. Note that each element in the list c_ins is a tuple with the input layer and the output flattened embedding layer. We pass the output to the next layer, in accordance to the functional API of Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden = dense_in(c_ins[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for each successive layer we combine the output of dense_in() on the next character with the output of dense_hidden() on the current hidden state, to create the new hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = add([c_dense, hidden])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the final hidden state through dense_out() gives us our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out = dense_out(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([c[0] for c in c_ins], c_out)\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75110/75110 [==============================] - 12s - loss: 2.5286    \n",
      "Epoch 2/12\n",
      "75110/75110 [==============================] - 11s - loss: 2.2554    \n",
      "Epoch 3/12\n",
      "75110/75110 [==============================] - 11s - loss: 2.1555    \n",
      "Epoch 4/12\n",
      "75110/75110 [==============================] - 11s - loss: 2.0909    \n",
      "Epoch 5/12\n",
      "75110/75110 [==============================] - 11s - loss: 2.0407    \n",
      "Epoch 6/12\n",
      "75110/75110 [==============================] - 11s - loss: 1.9984    \n",
      "Epoch 7/12\n",
      "75110/75110 [==============================] - 11s - loss: 1.9594    \n",
      "Epoch 8/12\n",
      "75110/75110 [==============================] - 11s - loss: 1.9243    \n",
      "Epoch 9/12\n",
      "75110/75110 [==============================] - 11s - loss: 1.8952    \n",
      "Epoch 10/12\n",
      "75110/75110 [==============================] - 11s - loss: 1.8665    \n",
      "Epoch 11/12\n",
      "75110/75110 [==============================] - 11s - loss: 1.8419    \n",
      "Epoch 12/12\n",
      "75110/75110 [==============================] - 11s - loss: 1.8193    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20343d93a58>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, y, batch_size = 64, epochs = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we define a function to predict the next chracter of a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [np.array(char_indices[c])[np.newaxis] for c in inp]\n",
    "    p = model.predict(idxs)\n",
    "    return chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we use some examples to test the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('this is ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to work great again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First RNN with high level parts of Keras API\n",
    "\n",
    "We recreate the recurrent neural network using the higher level api of Keras, instead of doing it manually with the functional api."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the number of hidden layers, factors, character steps and vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden, n_fac, cs, vocab_size = (256, 42, 8, 86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define the model using the sequential API and the SimpleRNN class.\n",
    "\n",
    "Again, note that we initialise the weights using the identity matrix rather than eg. Xavier initialisation. That way we start out by having the hidden state stay the same for each layer of the RNN. That makes intuitive sense, as absent of any new information, we would imagine each layer to be the same. It also makes sense from an empirical point of view, as demonstrated by this paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length = cs),\n",
    "    SimpleRNN(n_hidden, activation = 'relu', recurrent_initializer = 'identity'),\n",
    "    Dense(vocab_size, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 8, 42)             3612      \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 256)               76544     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 86)                22102     \n",
      "=================================================================\n",
      "Total params: 102,258\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75110/75110 [==============================] - 7s - loss: 2.7996     \n",
      "Epoch 2/12\n",
      "75110/75110 [==============================] - 7s - loss: 2.2896     \n",
      "Epoch 3/12\n",
      "75110/75110 [==============================] - 7s - loss: 2.0770     \n",
      "Epoch 4/12\n",
      "75110/75110 [==============================] - 7s - loss: 1.9387     \n",
      "Epoch 5/12\n",
      "75110/75110 [==============================] - 7s - loss: 1.8312     \n",
      "Epoch 6/12\n",
      "75110/75110 [==============================] - 7s - loss: 1.7478     \n",
      "Epoch 7/12\n",
      "75110/75110 [==============================] - 7s - loss: 1.6823     \n",
      "Epoch 8/12\n",
      "75110/75110 [==============================] - 7s - loss: 1.6273     \n",
      "Epoch 9/12\n",
      "75110/75110 [==============================] - 7s - loss: 1.5802     \n",
      "Epoch 10/12\n",
      "75110/75110 [==============================] - 8s - loss: 1.5378     \n",
      "Epoch 11/12\n",
      "75110/75110 [==============================] - 7s - loss: 1.5004     \n",
      "Epoch 12/12\n",
      "75110/75110 [==============================] - 7s - loss: 1.4682     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2019a6cdeb8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.concatenate(xs, axis = 1), y, batch_size = 64, epochs = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then test the model. Again, define a function returning the predicted character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_keras(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = np.array(idxs)[np.newaxis,:]\n",
    "    p = model.predict(arrs)[0]\n",
    "    return chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('this is ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning sequences using low level part of Keras API\n",
    "\n",
    "We now predict each character to a given sequence length using the previous characters. We move the output generation inside the loop and make it part of the RNN. So everytime we loop through the RNN, we predict the next character. I.e. we predict char 2 using char 1 and predict char 3 using char 1 and 2 and predict char 4 using char 1, char 2 and char 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a sequence model, we can leave our input unchanged - but we have to change our output to a sequence (of course!)\n",
    "Here, c_out_dat is identical to c_in_dat, but moved across 1 character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Previous\n",
    "#c_in_dat = [[idx[i + n] for i in xrange(0, len(idx) - 1 - cs, cs)]\n",
    "#            for n in range(cs)]\n",
    "# Now\n",
    "c_out_dat = [[idx[i + n] for i in range(1, len(idx) - cs, cs)]\n",
    "             for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now also have a sequence of outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = [np.stack(c[:-2]) for c in c_out_dat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading down each column shows one set of inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[40],\n",
       "        [ 1],\n",
       "        [33],\n",
       "        [ 2],\n",
       "        [72],\n",
       "        [67],\n",
       "        [73],\n",
       "        [ 2]]), array([[42],\n",
       "        [ 1],\n",
       "        [38],\n",
       "        [44],\n",
       "        [ 2],\n",
       "        [ 9],\n",
       "        [61],\n",
       "        [73]]), array([[29],\n",
       "        [43],\n",
       "        [31],\n",
       "        [71],\n",
       "        [54],\n",
       "        [ 9],\n",
       "        [58],\n",
       "        [61]]), array([[30],\n",
       "        [45],\n",
       "        [ 2],\n",
       "        [74],\n",
       "        [ 2],\n",
       "        [76],\n",
       "        [67],\n",
       "        [58]]), array([[25],\n",
       "        [40],\n",
       "        [73],\n",
       "        [73],\n",
       "        [76],\n",
       "        [61],\n",
       "        [24],\n",
       "        [71]]), array([[27],\n",
       "        [40],\n",
       "        [61],\n",
       "        [61],\n",
       "        [68],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [58]]), array([[29],\n",
       "        [39],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [66],\n",
       "        [73],\n",
       "        [33],\n",
       "        [ 2]]), array([[ 1],\n",
       "        [43],\n",
       "        [73],\n",
       "        [62],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [72],\n",
       "        [67]])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[xs[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([42,  1, 38, 44,  2,  9, 61, 73]),\n",
       " array([29, 43, 31, 71, 54,  9, 58, 61]),\n",
       " array([30, 45,  2, 74,  2, 76, 67, 58]),\n",
       " array([25, 40, 73, 73, 76, 61, 24, 71]),\n",
       " array([27, 40, 61, 61, 68, 54,  2, 58]),\n",
       " array([29, 39, 54,  2, 66, 73, 33,  2]),\n",
       " array([ 1, 43, 73, 62, 54,  2, 72, 67]),\n",
       " array([ 1, 33,  2, 72, 67, 73,  2, 68])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ys[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the input, hidden and output layers again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation = 'relu')\n",
    "dense_hidden = Dense(n_hidden, activation = 'relu', kernel_initializer = 'identity')\n",
    "dense_out = Dense(vocab_size, activation = 'softmax', name = 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to pass a vector of all zeros as our starting point - below's our input layers for that: So we have moved the first character inside the loop and now just initialise the hidden lyaer with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp1 = Input(shape = (n_fac,), name = 'zeros')\n",
    "hidden = dense_in(inp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define the 8 layers. Note that we create a list of each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outs = []\n",
    "\n",
    "for i in range(cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = add([c_dense, hidden])\n",
    "    # every layer now has an output\n",
    "    outs.append(dense_out(hidden))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define and compile the model. Compared to the previous model, where we just predicted the final character of a sequence, out model specification now has two changes. 1) The out put is a list of 8 outputs, and 2) We add the first zero layer to our list of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([inp1] + [c[0] for c in c_ins], outs)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pad out input layers, so we do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75110, 42)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = np.tile(np.zeros(n_fac), (len(xs[0]), 1))\n",
    "zeros.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75110/75110 [==============================] - 24s - loss: 20.1545 - output_loss_1: 2.7184 - output_loss_2: 2.5713 - output_loss_3: 2.5230 - output_loss_4: 2.4816 - output_loss_5: 2.4761 - output_loss_6: 2.4637 - output_loss_7: 2.4718 - output_loss_8: 2.4487    \n",
      "Epoch 2/12\n",
      "75110/75110 [==============================] - 22s - loss: 17.8824 - output_loss_1: 2.5128 - output_loss_2: 2.3520 - output_loss_3: 2.2396 - output_loss_4: 2.1765 - output_loss_5: 2.1618 - output_loss_6: 2.1446 - output_loss_7: 2.1627 - output_loss_8: 2.1326    \n",
      "Epoch 3/12\n",
      "75110/75110 [==============================] - 22s - loss: 17.2624 - output_loss_1: 2.4962 - output_loss_2: 2.3309 - output_loss_3: 2.1750 - output_loss_4: 2.0874 - output_loss_5: 2.0590 - output_loss_6: 2.0359 - output_loss_7: 2.0516 - output_loss_8: 2.0263    \n",
      "Epoch 4/12\n",
      "75110/75110 [==============================] - 22s - loss: 16.8776 - output_loss_1: 2.4895 - output_loss_2: 2.3220 - output_loss_3: 2.1435 - output_loss_4: 2.0337 - output_loss_5: 1.9911 - output_loss_6: 1.9652 - output_loss_7: 1.9783 - output_loss_8: 1.9543    \n",
      "Epoch 5/12\n",
      "75110/75110 [==============================] - 22s - loss: 16.6157 - output_loss_1: 2.4859 - output_loss_2: 2.3166 - output_loss_3: 2.1241 - output_loss_4: 1.9978 - output_loss_5: 1.9461 - output_loss_6: 1.9136 - output_loss_7: 1.9274 - output_loss_8: 1.9041    \n",
      "Epoch 6/12\n",
      "75110/75110 [==============================] - 22s - loss: 16.4240 - output_loss_1: 2.4843 - output_loss_2: 2.3116 - output_loss_3: 2.1109 - output_loss_4: 1.9695 - output_loss_5: 1.9140 - output_loss_6: 1.8759 - output_loss_7: 1.8904 - output_loss_8: 1.8674    \n",
      "Epoch 7/12\n",
      "75110/75110 [==============================] - 22s - loss: 16.2813 - output_loss_1: 2.4815 - output_loss_2: 2.3114 - output_loss_3: 2.1013 - output_loss_4: 1.9526 - output_loss_5: 1.8884 - output_loss_6: 1.8483 - output_loss_7: 1.8608 - output_loss_8: 1.8371    \n",
      "Epoch 8/12\n",
      "75110/75110 [==============================] - 22s - loss: 16.1630 - output_loss_1: 2.4801 - output_loss_2: 2.3079 - output_loss_3: 2.0959 - output_loss_4: 1.9378 - output_loss_5: 1.8677 - output_loss_6: 1.8236 - output_loss_7: 1.8377 - output_loss_8: 1.8124    \n",
      "Epoch 9/12\n",
      "75110/75110 [==============================] - 22s - loss: 16.0693 - output_loss_1: 2.4795 - output_loss_2: 2.3060 - output_loss_3: 2.0912 - output_loss_4: 1.9262 - output_loss_5: 1.8515 - output_loss_6: 1.8052 - output_loss_7: 1.8172 - output_loss_8: 1.7926    \n",
      "Epoch 10/12\n",
      "75110/75110 [==============================] - 22s - loss: 15.9856 - output_loss_1: 2.4789 - output_loss_2: 2.3048 - output_loss_3: 2.0859 - output_loss_4: 1.9152 - output_loss_5: 1.8362 - output_loss_6: 1.7898 - output_loss_7: 1.7991 - output_loss_8: 1.7757    \n",
      "Epoch 11/12\n",
      "75110/75110 [==============================] - 22s - loss: 15.9169 - output_loss_1: 2.4775 - output_loss_2: 2.3034 - output_loss_3: 2.0810 - output_loss_4: 1.9077 - output_loss_5: 1.8248 - output_loss_6: 1.7758 - output_loss_7: 1.7857 - output_loss_8: 1.7611    \n",
      "Epoch 12/12\n",
      "75110/75110 [==============================] - 23s - loss: 15.8577 - output_loss_1: 2.4772 - output_loss_2: 2.3038 - output_loss_3: 2.0790 - output_loss_4: 1.8998 - output_loss_5: 1.8130 - output_loss_6: 1.7637 - output_loss_7: 1.7725 - output_loss_8: 1.7488    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2036006e320>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([zeros] + xs, ys, batch_size = 64, epochs = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again define a model returning predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict([np.zeros(n_fac)[np.newaxis,:]] + arrs)\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the model on our examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 't', ' ', 's', 'n', ' ']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 'a', 'r', 't', ' ', 'o', 'f', ' ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e', 'n', 'a', 'i', 'o', 'f', ' ', 't']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q', 'u', 'e', 'e', 'n', 's', ' ', 'a']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['u', 'e', 'r', 't', 't', ' ', 't', 'n']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, going forward one character at a time, it seems to work pretty good all things considered!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return sequences using high level part of Keras API\n",
    "\n",
    "We then create a return sequence model using the highest level Keras API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reuse the number of hidden layers, factors, character steps and vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 42, 8, 86)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden, n_fac, cs, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert our previous keras model into a sequence model, simply add the 'return_sequences = True' parameter, and add TimeDistributed() around our dense layer. This is due to our output having 8x256 dimensions instead of 1x256 in a usual dense layer. This is due to us generating 8 outputs. So TimeDistributed() ensures that we get a dense layer for each of the 8 outputs, which will share the same weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length = cs),\n",
    "    SimpleRNN(n_hidden, return_sequences = True, activation = 'relu',\n",
    "              recurrent_initializer = 'identity'),\n",
    "    TimeDistributed(Dense(vocab_size, activation = 'softmax')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 8, 42)             3612      \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 8, 256)            76544     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 8, 86)             22102     \n",
      "=================================================================\n",
      "Total params: 102,258\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create the model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75110,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = [np.stack(c[:-2]) for c in c_in_dat]\n",
    "xs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine ys, as we added a dimension earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75110,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = [np.stack(c[:-2]) for c in c_out_dat]\n",
    "ys[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_rnn = np.stack(xs, axis = 1)\n",
    "y_rnn = np.expand_dims(np.stack(ys, axis = 1), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yielding the expected shape of ((75110, 8), (75110, 8, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75110, 8), (75110, 8, 1))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rnn.shape, y_rnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then train the model and see that we obtain similar loss as earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75110/75110 [==============================] - 8s - loss: 2.4326     \n",
      "Epoch 2/8\n",
      "75110/75110 [==============================] - 7s - loss: 2.0038     \n",
      "Epoch 3/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.8861     \n",
      "Epoch 4/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.8250     \n",
      "Epoch 5/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.7869     \n",
      "Epoch 6/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.7608     \n",
      "Epoch 7/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.7406     \n",
      "Epoch 8/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.7246     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x203631458d0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn, y_rnn, batch_size = 64, epochs = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can then test by defining the test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_keras(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arr = np.array(idxs)[np.newaxis,:]\n",
    "    p = model.predict(arr)[0]\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a', 'h', 'e', 'n', ' ', 'p', 's', ' ']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_keras(' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 'a', 'r', 't', ' ', 'o', 'f', ' ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e', 'r', 't', 'i', 'o', 'f', ' ', 't']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_keras('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q', 'u', 'e', 'e', 'n', 's', ' ', 'a']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['u', 'i', 's', 'n', 't', ' ', 't', 'n']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_keras('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Again a pretty good result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful model in Keras\n",
    "\n",
    "How do we add state to a RNN? How to generate a model, that can handle long term dependencies?\n",
    "\n",
    "We alter the previous model by 1) not shuffling the input data and 2) stopping passing in zeroes for each itteration. That is we want to keep the hidden state for each itteration of 8 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A stateful model is easy to create (just add \"stateful=True\") but harder to train. We had to add batchnorm and use LSTM to get reasonable results. It is because we get activate using the weight matrix for each loop of the RNN. This yields hundred of  thousands weights in the state matrix. The training was solved in the LSTM model, where we use a neural net inside the loop, that decides how much of the state matrix to keep and how much to use at each activation.\n",
    "\n",
    "When using stateful in keras, you have to also add 'batch_input_shape' to the first layer, and fix the batch size there.\n",
    "\n",
    "This model, when shuffling is set to false, allows a build up of arbitrarily long dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length = cs, batch_input_shape = (bs, 8)),\n",
    "    BatchNormalization(),\n",
    "    LSTM(n_hidden, return_sequences = True, stateful = True),\n",
    "    TimeDistributed(Dense(vocab_size, activation = 'softmax')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're using a fixed batch shape, we have to ensure our inputs and outputs are a even multiple of the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mx = len(x_rnn) // bs * bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then fit the model, remembering that Shuffle has to be set as False, as the ordering of the data now has to be ensured in order to estimate the long term dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "75072/75072 [==============================] - 25s - loss: 2.2617    \n",
      "Epoch 2/4\n",
      "75072/75072 [==============================] - 24s - loss: 1.9948    \n",
      "Epoch 3/4\n",
      "75072/75072 [==============================] - 23s - loss: 1.9167    \n",
      "Epoch 4/4\n",
      "75072/75072 [==============================] - 24s - loss: 1.8712    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20366294828>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size = bs, epochs = 4, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We lower the learning rate and run for some more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75072/75072 [==============================] - 24s - loss: 1.8388    \n",
      "Epoch 2/8\n",
      "75072/75072 [==============================] - 24s - loss: 1.8134    \n",
      "Epoch 3/8\n",
      "75072/75072 [==============================] - 24s - loss: 1.7923    \n",
      "Epoch 4/8\n",
      "75072/75072 [==============================] - 24s - loss: 1.7741    \n",
      "Epoch 5/8\n",
      "75072/75072 [==============================] - 23s - loss: 1.7582    \n",
      "Epoch 6/8\n",
      "75072/75072 [==============================] - 25s - loss: 1.7441    \n",
      "Epoch 7/8\n",
      "75072/75072 [==============================] - 24s - loss: 1.7311    \n",
      "Epoch 8/8\n",
      "75072/75072 [==============================] - 24s - loss: 1.7195    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x203664e3278>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "\n",
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size = bs, epochs = 8, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using the state keeping model makes us able to lower the loss quite a bit, compared to the model not keeping the state.\n",
    "\n",
    "We can do even better by adding a second RNN which uses the first RNN as input. See this in rnn-example.ipynb notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot sequence model with keras\n",
    "\n",
    "We have previously not one hot encoded ouroutput. This is due tio the fact that Keras impelements the sparse categorical crossentropy loss function, which is identical to categorical crossentropy, but takes an integer target instead of a binary one hot encoded target. This is usefull, when you have very large vocabularies with hundreds of thousands words.\n",
    "\n",
    "However, in order to make thins simpler, we will use one hot encoding, when creating our hand craftet Theano model. This is the keras version of the theano model that we're about to create.\n",
    "\n",
    "So below we use normal cross enthropy and use no embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        SimpleRNN(n_hidden, return_sequences = True, input_shape = (cs, vocab_size),\n",
    "                  activation = 'relu', recurrent_initializer = 'identity'),\n",
    "        TimeDistributed(Dense(vocab_size, activation = 'softmax')),\n",
    "    ])\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we do not use an embedding layer and we use normal categorical crossenthropy, we have to one hot encode out input and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75110, 8, 86), (75110, 8, 86))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_ys = [to_categorical(o, vocab_size) for o in ys]\n",
    "oh_y_rnn=np.stack(oh_ys, axis=1)\n",
    "\n",
    "oh_xs = [to_categorical(o, vocab_size) for o in xs]\n",
    "oh_x_rnn=np.stack(oh_xs, axis=1)\n",
    "\n",
    "oh_x_rnn.shape, oh_y_rnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then fit this model, an see that it performs on the same level as the model using embeddings and sparse categorical crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75110/75110 [==============================] - 8s - loss: 2.4501     \n",
      "Epoch 2/8\n",
      "75110/75110 [==============================] - 7s - loss: 2.0418     \n",
      "Epoch 3/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.9236     \n",
      "Epoch 4/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.8586     \n",
      "Epoch 5/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.8157     \n",
      "Epoch 6/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.7845     \n",
      "Epoch 7/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.7607     \n",
      "Epoch 8/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.7419     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20366a41ac8>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(oh_x_rnn, oh_y_rnn, batch_size = 64, epochs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_oh(inp):\n",
    "    idxs = np.array([char_indices[c] for c in inp])\n",
    "    arr = to_categorical(idxs, vocab_size)\n",
    "    p = model.predict(arr[np.newaxis,:])[0]\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 's', ' ', 'i', 'n', ' ']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_oh(' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 'a', 'r', 't', ' ', 'o', 'f', ' ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e', 'r', 't', ' ', 'o', 'f', ' ', 't']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_oh('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q', 'u', 'e', 'e', 'n', 's', ' ', 'a']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['u', 'e', 's', 'd', 'c', ' ', 'o', 'n']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_oh('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Theano RNN\n",
    "\n",
    "In this section we build an RNN in pure Theano, using one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00001\t#include <Python.h>\n",
      "00002\t#include \"theano_mod_helper.h\"\n",
      "00003\t#include \"structmember.h\"\n",
      "00004\t#include <sys/time.h>\n",
      "00005\t\n",
      "00006\t#if PY_VERSION_HEX >= 0x03000000\n",
      "00007\t#include \"numpy/npy_3kcompat.h\"\n",
      "00008\t#define PyCObject_AsVoidPtr  NpyCapsule_AsVoidPtr\n",
      "00009\t#define PyCObject_GetDesc  NpyCapsule_GetDesc\n",
      "00010\t#define PyCObject_Check NpyCapsule_Check\n",
      "00011\t#endif\n",
      "00012\t\n",
      "00013\t#ifndef Py_TYPE\n",
      "00014\t#define Py_TYPE(obj) obj->ob_type\n",
      "00015\t#endif\n",
      "00016\t\n",
      "00017\t/**\n",
      "00018\t\n",
      "00019\tTODO: \n",
      "00020\t- Check max supported depth of recursion\n",
      "00021\t- CLazyLinker should add context information to errors caught during evaluation. Say what node we were on, add the traceback attached to the node.\n",
      "00022\t- Clear containers of fully-useed intermediate results if allow_gc is 1\n",
      "00023\t- Add timers for profiling\n",
      "00024\t- Add support for profiling space used.\n",
      "00025\t\n",
      "00026\t\n",
      "00027\t  */\n",
      "00028\tstatic double pytime(const struct timeval * tv)\n",
      "00029\t{\n",
      "00030\t  struct timeval t;\n",
      "00031\t  if (!tv)\n",
      "00032\t    {\n",
      "00033\t      tv = &t;\n",
      "00034\t      gettimeofday(&t, NULL);\n",
      "00035\t    }\n",
      "00036\t  return (double) tv->tv_sec + (double) tv->tv_usec / 1000000.0;\n",
      "00037\t}\n",
      "00038\t\n",
      "00039\t/**\n",
      "00040\t  Helper routine to convert a PyList of integers to a c array of integers.\n",
      "00041\t  */\n",
      "00042\tstatic int unpack_list_of_ssize_t(PyObject * pylist, Py_ssize_t **dst, Py_ssize_t *len,\n",
      "00043\t                                  const char* kwname)\n",
      "00044\t{\n",
      "00045\t  Py_ssize_t buflen, *buf;\n",
      "00046\t  if (!PyList_Check(pylist))\n",
      "00047\t    {\n",
      "00048\t      PyErr_Format(PyExc_TypeError, \"%s must be list\", kwname);\n",
      "00049\t      return -1;\n",
      "00050\t    }\n",
      "00051\t  assert (NULL == *dst);\n",
      "00052\t  *len = buflen = PyList_Size(pylist);\n",
      "00053\t  *dst = buf = (Py_ssize_t*)calloc(buflen, sizeof(Py_ssize_t));\n",
      "00054\t  assert(buf);\n",
      "00055\t  for (int ii = 0; ii < buflen; ++ii)\n",
      "00056\t    {\n",
      "00057\t      PyObject * el_i = PyList_GetItem(pylist, ii);\n",
      "00058\t      Py_ssize_t n_i = PyNumber_AsSsize_t(el_i, PyExc_IndexError);\n",
      "00059\t      if (PyErr_Occurred())\n",
      "00060\t        {\n",
      "00061\t          free(buf);\n",
      "00062\t          *dst = NULL;\n",
      "00063\t          return -1;\n",
      "00064\t        }\n",
      "00065\t      buf[ii] = n_i;\n",
      "00066\t    }\n",
      "00067\t  return 0;\n",
      "00068\t}\n",
      "00069\t\n",
      "00070\t/**\n",
      "00071\t\n",
      "00072\t  CLazyLinker\n",
      "00073\t\n",
      "00074\t\n",
      "00075\t  */\n",
      "00076\ttypedef struct {\n",
      "00077\t    PyObject_HEAD\n",
      "00078\t    /* Type-specific fields go here. */\n",
      "00079\t    PyObject * nodes; // the python list of nodes\n",
      "00080\t    PyObject * thunks; // python list of thunks\n",
      "00081\t    PyObject * pre_call_clear; //list of cells to clear on call.\n",
      "00082\t    int allow_gc;\n",
      "00083\t    Py_ssize_t n_applies;\n",
      "00084\t    int n_vars;    // number of variables in the graph\n",
      "00085\t    int * var_computed; // 1 or 0 for every variable\n",
      "00086\t    PyObject ** var_computed_cells;\n",
      "00087\t    PyObject ** var_value_cells;\n",
      "00088\t    Py_ssize_t **dependencies; // list of vars dependencies for GC\n",
      "00089\t    Py_ssize_t *n_dependencies;\n",
      "00090\t\n",
      "00091\t    Py_ssize_t n_output_vars;\n",
      "00092\t    Py_ssize_t * output_vars; // variables that *must* be evaluated by call\n",
      "00093\t\n",
      "00094\t    int * is_lazy; // 1 or 0 for every thunk\n",
      "00095\t\n",
      "00096\t    Py_ssize_t * var_owner; // nodes[[var_owner[var_idx]]] is var[var_idx]->owner\n",
      "00097\t    int * var_has_owner; //  1 or 0\n",
      "00098\t\n",
      "00099\t    Py_ssize_t * node_n_inputs;\n",
      "00100\t    Py_ssize_t * node_n_outputs;\n",
      "00101\t    Py_ssize_t ** node_inputs;\n",
      "00102\t    Py_ssize_t ** node_outputs;\n",
      "00103\t    Py_ssize_t * node_inputs_outputs_base; // node_inputs and node_outputs point into this\n",
      "00104\t    Py_ssize_t * node_n_prereqs;\n",
      "00105\t    Py_ssize_t ** node_prereqs;\n",
      "00106\t\n",
      "00107\t    Py_ssize_t * update_storage; // input cells to update with the last outputs in output_vars\n",
      "00108\t    Py_ssize_t n_updates;\n",
      "00109\t\n",
      "00110\t    void ** thunk_cptr_fn;\n",
      "00111\t    void ** thunk_cptr_data;\n",
      "00112\t    PyObject * call_times;\n",
      "00113\t    PyObject * call_counts;\n",
      "00114\t    int do_timing;\n",
      "00115\t    int need_update_inputs;\n",
      "00116\t    int position_of_error; // -1 for no error, otw the index into `thunks` that failed.\n",
      "00117\t} CLazyLinker;\n",
      "00118\t\n",
      "00119\t\n",
      "00120\tstatic void\n",
      "00121\tCLazyLinker_dealloc(PyObject* _self)\n",
      "00122\t{\n",
      "00123\t  CLazyLinker* self = (CLazyLinker *) _self;\n",
      "00124\t  free(self->thunk_cptr_fn);\n",
      "00125\t  free(self->thunk_cptr_data);\n",
      "00126\t\n",
      "00127\t  free(self->is_lazy);\n",
      "00128\t\n",
      "00129\t  free(self->update_storage);\n",
      "00130\t\n",
      "00131\t  if (self->node_n_prereqs)\n",
      "00132\t    {\n",
      "00133\t      for (int i = 0; i < self->n_applies; ++i)\n",
      "00134\t        {\n",
      "00135\t          free(self->node_prereqs[i]);\n",
      "00136\t        }\n",
      "00137\t    }\n",
      "00138\t  free(self->node_n_prereqs);\n",
      "00139\t  free(self->node_prereqs);\n",
      "00140\t  free(self->node_inputs_outputs_base);\n",
      "00141\t  free(self->node_n_inputs);\n",
      "00142\t  free(self->node_n_outputs);\n",
      "00143\t  free(self->node_inputs);\n",
      "00144\t  free(self->node_outputs);\n",
      "00145\t\n",
      "00146\t  if (self->dependencies)\n",
      "00147\t    {\n",
      "00148\t      for (int i = 0; i < self->n_vars; ++i)\n",
      "00149\t        {\n",
      "00150\t          free(self->dependencies[i]);\n",
      "00151\t        }\n",
      "00152\t      free(self->dependencies);\n",
      "00153\t      free(self->n_dependencies);\n",
      "00154\t    }\n",
      "00155\t\n",
      "00156\t  free(self->var_owner);\n",
      "00157\t  free(self->var_has_owner);\n",
      "00158\t  free(self->var_computed);\n",
      "00159\t  if (self->var_computed_cells)\n",
      "00160\t    {\n",
      "00161\t      for (int i = 0; i < self->n_vars; ++i)\n",
      "00162\t        {\n",
      "00163\t          Py_DECREF(self->var_computed_cells[i]);\n",
      "00164\t          Py_DECREF(self->var_value_cells[i]);\n",
      "00165\t        }\n",
      "00166\t    }\n",
      "00167\t  free(self->var_computed_cells);\n",
      "00168\t  free(self->var_value_cells);\n",
      "00169\t  free(self->output_vars);\n",
      "00170\t\n",
      "00171\t  Py_XDECREF(self->nodes);\n",
      "00172\t  Py_XDECREF(self->thunks);\n",
      "00173\t  Py_XDECREF(self->call_times);\n",
      "00174\t  Py_XDECREF(self->call_counts);\n",
      "00175\t  Py_XDECREF(self->pre_call_clear);\n",
      "00176\t  Py_TYPE(self)->tp_free((PyObject*)self);\n",
      "00177\t}\n",
      "00178\tstatic PyObject *\n",
      "00179\tCLazyLinker_new(PyTypeObject *type, PyObject *args, PyObject *kwds)\n",
      "00180\t{\n",
      "00181\t    CLazyLinker *self;\n",
      "00182\t\n",
      "00183\t    self = (CLazyLinker *)type->tp_alloc(type, 0);\n",
      "00184\t    if (self != NULL) {\n",
      "00185\t      self->nodes = NULL;\n",
      "00186\t      self->thunks = NULL;\n",
      "00187\t      self->pre_call_clear = NULL;\n",
      "00188\t\n",
      "00189\t      self->allow_gc = 1;\n",
      "00190\t      self->n_applies = 0;\n",
      "00191\t      self->n_vars = 0;\n",
      "00192\t      self->var_computed = NULL;\n",
      "00193\t      self->var_computed_cells = NULL;\n",
      "00194\t      self->var_value_cells = NULL;\n",
      "00195\t      self->dependencies = NULL;\n",
      "00196\t      self->n_dependencies = NULL;\n",
      "00197\t\n",
      "00198\t      self->n_output_vars = 0;\n",
      "00199\t      self->output_vars = NULL;\n",
      "00200\t\n",
      "00201\t      self->is_lazy = NULL;\n",
      "00202\t\n",
      "00203\t      self->var_owner = NULL;\n",
      "00204\t      self->var_has_owner = NULL;\n",
      "00205\t\n",
      "00206\t      self->node_n_inputs = NULL;\n",
      "00207\t      self->node_n_outputs = NULL;\n",
      "00208\t      self->node_inputs = NULL;\n",
      "00209\t      self->node_outputs = NULL;\n",
      "00210\t      self->node_inputs_outputs_base = NULL;\n",
      "00211\t      self->node_prereqs = NULL;\n",
      "00212\t      self->node_n_prereqs = NULL;\n",
      "00213\t\n",
      "00214\t      self->update_storage = NULL;\n",
      "00215\t      self->n_updates = 0;\n",
      "00216\t\n",
      "00217\t      self->thunk_cptr_data = NULL;\n",
      "00218\t      self->thunk_cptr_fn = NULL;\n",
      "00219\t      self->call_times = NULL;\n",
      "00220\t      self->call_counts = NULL;\n",
      "00221\t      self->do_timing = 0;\n",
      "00222\t\n",
      "00223\t      self->need_update_inputs = 0;\n",
      "00224\t      self->position_of_error = -1;\n",
      "00225\t    }\n",
      "00226\t    return (PyObject *)self;\n",
      "00227\t}\n",
      "00228\t\n",
      "00229\tstatic int\n",
      "00230\tCLazyLinker_init(CLazyLinker *self, PyObject *args, PyObject *kwds)\n",
      "00231\t{\n",
      "00232\t    static char *kwlist[] = {\n",
      "00233\t      (char*)\"nodes\",\n",
      "00234\t      (char*)\"thunks\",\n",
      "00235\t      (char*)\"pre_call_clear\",\n",
      "00236\t      (char*)\"allow_gc\",\n",
      "00237\t      (char*)\"call_counts\",\n",
      "00238\t      (char*)\"call_times\",\n",
      "00239\t      (char*)\"compute_map_list\",\n",
      "00240\t      (char*)\"storage_map_list\",\n",
      "00241\t      (char*)\"base_input_output_list\",\n",
      "00242\t      (char*)\"node_n_inputs\",\n",
      "00243\t      (char*)\"node_n_outputs\",\n",
      "00244\t      (char*)\"node_input_offset\",\n",
      "00245\t      (char*)\"node_output_offset\",\n",
      "00246\t      (char*)\"var_owner\",\n",
      "00247\t      (char*)\"is_lazy_list\",\n",
      "00248\t      (char*)\"output_vars\",\n",
      "00249\t      (char*)\"node_prereqs\",\n",
      "00250\t      (char*)\"node_output_size\",\n",
      "00251\t      (char*)\"update_storage\",\n",
      "00252\t      (char*)\"dependencies\",\n",
      "00253\t      NULL};\n",
      "00254\t\n",
      "00255\t    PyObject *compute_map_list=NULL,\n",
      "00256\t             *storage_map_list=NULL,\n",
      "00257\t             *base_input_output_list=NULL,\n",
      "00258\t             *node_n_inputs=NULL,\n",
      "00259\t             *node_n_outputs=NULL,\n",
      "00260\t             *node_input_offset=NULL,\n",
      "00261\t             *node_output_offset=NULL,\n",
      "00262\t             *var_owner=NULL,\n",
      "00263\t             *is_lazy=NULL,\n",
      "00264\t             *output_vars=NULL,\n",
      "00265\t             *node_prereqs=NULL,\n",
      "00266\t             *node_output_size=NULL,\n",
      "00267\t             *update_storage=NULL,\n",
      "00268\t             *dependencies=NULL;\n",
      "00269\t\n",
      "00270\t    assert(!self->nodes);\n",
      "00271\t    if (! PyArg_ParseTupleAndKeywords(args, kwds, \"OOOiOOOOOOOOOOOOOOOO\", kwlist,\n",
      "00272\t                                      &self->nodes,\n",
      "00273\t                                      &self->thunks,\n",
      "00274\t                                      &self->pre_call_clear,\n",
      "00275\t                                      &self->allow_gc,\n",
      "00276\t                                      &self->call_counts,\n",
      "00277\t                                      &self->call_times,\n",
      "00278\t                                      &compute_map_list,\n",
      "00279\t                                      &storage_map_list,\n",
      "00280\t                                      &base_input_output_list,\n",
      "00281\t                                      &node_n_inputs,\n",
      "00282\t                                      &node_n_outputs,\n",
      "00283\t                                      &node_input_offset,\n",
      "00284\t                                      &node_output_offset,\n",
      "00285\t                                      &var_owner,\n",
      "00286\t                                      &is_lazy,\n",
      "00287\t                                      &output_vars,\n",
      "00288\t                                      &node_prereqs,\n",
      "00289\t                                      &node_output_size,\n",
      "00290\t                                      &update_storage,\n",
      "00291\t                                      &dependencies\n",
      "00292\t                                      ))\n",
      "00293\t        return -1;\n",
      "00294\t    Py_INCREF(self->nodes);\n",
      "00295\t    Py_INCREF(self->thunks);\n",
      "00296\t    Py_INCREF(self->pre_call_clear);\n",
      "00297\t    Py_INCREF(self->call_counts);\n",
      "00298\t    Py_INCREF(self->call_times);\n",
      "00299\t\n",
      "00300\t    Py_ssize_t n_applies = PyList_Size(self->nodes);\n",
      "00301\t\n",
      "00302\t    self->n_applies = n_applies;\n",
      "00303\t    self->n_vars = PyList_Size(var_owner);\n",
      "00304\t\n",
      "00305\t    if (PyList_Size(self->thunks) != n_applies) return -1;\n",
      "00306\t    if (PyList_Size(self->call_counts) != n_applies) return -1;\n",
      "00307\t    if (PyList_Size(self->call_times) != n_applies) return -1;\n",
      "00308\t\n",
      "00309\t    // allocated and initialize thunk_cptr_data and thunk_cptr_fn\n",
      "00310\t    if (n_applies)\n",
      "00311\t      {\n",
      "00312\t        self->thunk_cptr_data = (void**)calloc(n_applies, sizeof(void*));\n",
      "00313\t        self->thunk_cptr_fn = (void**)calloc(n_applies, sizeof(void*));\n",
      "00314\t        self->is_lazy = (int*)calloc(n_applies, sizeof(int));\n",
      "00315\t        self->node_prereqs = (Py_ssize_t**)calloc(n_applies, sizeof(Py_ssize_t*));\n",
      "00316\t        self->node_n_prereqs = (Py_ssize_t*)calloc(n_applies, sizeof(Py_ssize_t));\n",
      "00317\t        assert(self->node_prereqs);\n",
      "00318\t        assert(self->node_n_prereqs);\n",
      "00319\t        assert(self->is_lazy);\n",
      "00320\t        assert(self->thunk_cptr_fn);\n",
      "00321\t        assert(self->thunk_cptr_data);\n",
      "00322\t\n",
      "00323\t        for (int i = 0; i < n_applies; ++i)\n",
      "00324\t          {\n",
      "00325\t            PyObject * thunk = PyList_GetItem(self->thunks, i);\n",
      "00326\t            //thunk is borrowed\n",
      "00327\t            if (PyObject_HasAttrString(thunk, \"cthunk\"))\n",
      "00328\t              {\n",
      "00329\t                PyObject * cthunk = PyObject_GetAttrString(thunk, \"cthunk\");\n",
      "00330\t                //new reference\n",
      "00331\t                assert (cthunk && PyCObject_Check(cthunk));\n",
      "00332\t                self->thunk_cptr_fn[i] = PyCObject_AsVoidPtr(cthunk);\n",
      "00333\t                self->thunk_cptr_data[i] = PyCObject_GetDesc(cthunk);\n",
      "00334\t                Py_DECREF(cthunk);\n",
      "00335\t                // cthunk is kept alive by membership in self->thunks\n",
      "00336\t              }\n",
      "00337\t\n",
      "00338\t            PyObject * el_i = PyList_GetItem(is_lazy, i);\n",
      "00339\t            self->is_lazy[i] = PyNumber_AsSsize_t(el_i, NULL);\n",
      "00340\t\n",
      "00341\t            /* now get the prereqs */\n",
      "00342\t            el_i = PyList_GetItem(node_prereqs, i);\n",
      "00343\t            assert (PyList_Check(el_i));\n",
      "00344\t            self->node_n_prereqs[i] = PyList_Size(el_i);\n",
      "00345\t            if (self->node_n_prereqs[i])\n",
      "00346\t              {\n",
      "00347\t                self->node_prereqs[i] = (Py_ssize_t*)malloc(\n",
      "00348\t                              PyList_Size(el_i)*sizeof(Py_ssize_t));\n",
      "00349\t                for (int j = 0; j < PyList_Size(el_i); ++j)\n",
      "00350\t                  {\n",
      "00351\t                    PyObject * el_ij = PyList_GetItem(el_i, j);\n",
      "00352\t                    Py_ssize_t N = PyNumber_AsSsize_t(el_ij, PyExc_IndexError);\n",
      "00353\t                    if (PyErr_Occurred())\n",
      "00354\t                      return -1;\n",
      "00355\t                    // N < n. variables\n",
      "00356\t                    assert(N < PyList_Size(var_owner));\n",
      "00357\t                    self->node_prereqs[i][j] = N;\n",
      "00358\t                  }\n",
      "00359\t              }\n",
      "00360\t          }\n",
      "00361\t      }\n",
      "00362\t    if (PyList_Check(base_input_output_list))\n",
      "00363\t      {\n",
      "00364\t        Py_ssize_t n_inputs_outputs_base = PyList_Size(base_input_output_list);\n",
      "00365\t        self->node_inputs_outputs_base = (Py_ssize_t*)calloc(n_inputs_outputs_base,sizeof(Py_ssize_t));\n",
      "00366\t        assert(self->node_inputs_outputs_base);\n",
      "00367\t        for (int i = 0; i < n_inputs_outputs_base; ++i)\n",
      "00368\t          {\n",
      "00369\t            PyObject *el_i = PyList_GetItem(base_input_output_list, i);\n",
      "00370\t            Py_ssize_t idx = PyNumber_AsSsize_t(el_i, PyExc_IndexError);\n",
      "00371\t            if (PyErr_Occurred()) return -1;\n",
      "00372\t            self->node_inputs_outputs_base[i] = idx;\n",
      "00373\t          }\n",
      "00374\t        self->node_n_inputs = (Py_ssize_t*)calloc(n_applies,sizeof(Py_ssize_t));\n",
      "00375\t        assert(self->node_n_inputs);\n",
      "00376\t        self->node_n_outputs = (Py_ssize_t*)calloc(n_applies,sizeof(Py_ssize_t));\n",
      "00377\t        assert(self->node_n_outputs);\n",
      "00378\t        self->node_inputs = (Py_ssize_t**)calloc(n_applies,sizeof(Py_ssize_t*));\n",
      "00379\t        assert(self->node_inputs);\n",
      "00380\t        self->node_outputs = (Py_ssize_t**)calloc(n_applies,sizeof(Py_ssize_t*));\n",
      "00381\t        assert(self->node_outputs);\n",
      "00382\t        for (int i = 0; i < n_applies; ++i)\n",
      "00383\t          {\n",
      "00384\t            Py_ssize_t N;\n",
      "00385\t            N = PyNumber_AsSsize_t(PyList_GetItem(node_n_inputs, i),PyExc_IndexError);\n",
      "00386\t            if (PyErr_Occurred()) return -1;\n",
      "00387\t            assert (N <= n_inputs_outputs_base);\n",
      "00388\t            self->node_n_inputs[i] = N;\n",
      "00389\t            N = PyNumber_AsSsize_t(PyList_GetItem(node_n_outputs, i),PyExc_IndexError);\n",
      "00390\t            if (PyErr_Occurred()) return -1;\n",
      "00391\t            assert (N <= n_inputs_outputs_base);\n",
      "00392\t            self->node_n_outputs[i] = N;\n",
      "00393\t            N = PyNumber_AsSsize_t(PyList_GetItem(node_input_offset, i),PyExc_IndexError);\n",
      "00394\t            if (PyErr_Occurred()) return -1;\n",
      "00395\t            assert (N <= n_inputs_outputs_base);\n",
      "00396\t            self->node_inputs[i] = &self->node_inputs_outputs_base[N];\n",
      "00397\t            N = PyNumber_AsSsize_t(PyList_GetItem(node_output_offset, i),PyExc_IndexError);\n",
      "00398\t            if (PyErr_Occurred()) return -1;\n",
      "00399\t            assert (N <= n_inputs_outputs_base);\n",
      "00400\t            self->node_outputs[i] = &self->node_inputs_outputs_base[N];\n",
      "00401\t          }\n",
      "00402\t      }\n",
      "00403\t    else\n",
      "00404\t      {\n",
      "00405\t        PyErr_SetString(PyExc_TypeError, \"base_input_output_list must be list\");\n",
      "00406\t        return -1;\n",
      "00407\t      }\n",
      "00408\t\n",
      "00409\t    // allocation for var_owner\n",
      "00410\t    if (PyList_Check(var_owner))\n",
      "00411\t      {\n",
      "00412\t        self->var_owner = (Py_ssize_t*)calloc(self->n_vars,sizeof(Py_ssize_t));\n",
      "00413\t        self->var_has_owner = (int*)calloc(self->n_vars,sizeof(int));\n",
      "00414\t        self->var_computed = (int*)calloc(self->n_vars,sizeof(int));\n",
      "00415\t        self->var_computed_cells = (PyObject**)calloc(self->n_vars,sizeof(PyObject*));\n",
      "00416\t        self->var_value_cells = (PyObject**)calloc(self->n_vars,sizeof(PyObject*));\n",
      "00417\t        for (int i = 0; i < self->n_vars; ++i)\n",
      "00418\t          {\n",
      "00419\t            PyObject * el_i = PyList_GetItem(var_owner, i);\n",
      "00420\t            if (el_i == Py_None)\n",
      "00421\t              {\n",
      "00422\t                self->var_has_owner[i] = 0;\n",
      "00423\t              }\n",
      "00424\t            else\n",
      "00425\t              {\n",
      "00426\t                Py_ssize_t N = PyNumber_AsSsize_t(el_i, PyExc_IndexError);\n",
      "00427\t                if (PyErr_Occurred()) return -1;\n",
      "00428\t                assert (N <= n_applies);\n",
      "00429\t                self->var_owner[i] = N;\n",
      "00430\t                self->var_has_owner[i] = 1;\n",
      "00431\t              }\n",
      "00432\t            self->var_computed_cells[i] = PyList_GetItem(compute_map_list, i);\n",
      "00433\t            Py_INCREF(self->var_computed_cells[i]);\n",
      "00434\t            self->var_value_cells[i] = PyList_GetItem(storage_map_list, i);\n",
      "00435\t            Py_INCREF(self->var_value_cells[i]);\n",
      "00436\t          }\n",
      "00437\t      }\n",
      "00438\t    else\n",
      "00439\t      {\n",
      "00440\t        PyErr_SetString(PyExc_TypeError, \"var_owner must be list\");\n",
      "00441\t        return -1;\n",
      "00442\t      }\n",
      "00443\t\n",
      "00444\t    if (dependencies != Py_None)\n",
      "00445\t      {\n",
      "00446\t        self->dependencies = (Py_ssize_t**)calloc(self->n_vars, sizeof(Py_ssize_t *));\n",
      "00447\t        self->n_dependencies = (Py_ssize_t*)calloc(self->n_vars, sizeof(Py_ssize_t));\n",
      "00448\t        assert(self->dependencies);\n",
      "00449\t        assert(self->n_dependencies);\n",
      "00450\t\n",
      "00451\t        for (int i = 0; i < self->n_vars; ++i)\n",
      "00452\t          {\n",
      "00453\t            PyObject *tmp = PyList_GetItem(dependencies, i);\n",
      "00454\t            // refcounting - tmp is borrowed\n",
      "00455\t            if (unpack_list_of_ssize_t(tmp, &self->dependencies[i], &self->n_dependencies[i],\n",
      "00456\t                                       \"dependencies\"))\n",
      "00457\t              return -1;\n",
      "00458\t          }\n",
      "00459\t      }\n",
      "00460\t\n",
      "00461\t    if (unpack_list_of_ssize_t(output_vars, &self->output_vars, &self->n_output_vars,\n",
      "00462\t                               \"output_vars\"))\n",
      "00463\t      return -1;\n",
      "00464\t    for (int i = 0; i < self->n_output_vars; ++i)\n",
      "00465\t      {\n",
      "00466\t        assert(self->output_vars[i] < self->n_vars);\n",
      "00467\t      }\n",
      "00468\t    if (unpack_list_of_ssize_t(update_storage, &self->update_storage, &self->n_updates,\n",
      "00469\t                               \"updates_storage\"))\n",
      "00470\t      return -1;\n",
      "00471\t    return 0;\n",
      "00472\t}\n",
      "00473\tstatic void set_position_of_error(CLazyLinker * self, int owner_idx)\n",
      "00474\t{\n",
      "00475\t  if (self->position_of_error == -1)\n",
      "00476\t    {\n",
      "00477\t      self->position_of_error = owner_idx;\n",
      "00478\t    }\n",
      "00479\t}\n",
      "00480\tstatic PyObject * pycall(CLazyLinker * self, Py_ssize_t node_idx, int verbose)\n",
      "00481\t{\n",
      "00482\t  // call thunk to see which inputs it wants\n",
      "00483\t  PyObject * thunk = PyList_GetItem(self->thunks, node_idx);\n",
      "00484\t  // refcounting - thunk is borrowed\n",
      "00485\t  PyObject * rval = NULL;\n",
      "00486\t  if (self->do_timing)\n",
      "00487\t    {\n",
      "00488\t      double t0 = pytime(NULL);\n",
      "00489\t      if (verbose) fprintf(stderr, \"calling via Python (node %i)\\n\", (int)node_idx);\n",
      "00490\t      rval = PyObject_CallObject(thunk, NULL);\n",
      "00491\t      if (rval)\n",
      "00492\t        {\n",
      "00493\t          double t1 = pytime(NULL);\n",
      "00494\t          double ti = PyFloat_AsDouble(\n",
      "00495\t                         PyList_GetItem(self->call_times, node_idx));\n",
      "00496\t          PyList_SetItem(self->call_times, node_idx,\n",
      "00497\t                         PyFloat_FromDouble(t1 - t0 + ti));\n",
      "00498\t          PyObject * count = PyList_GetItem(self->call_counts, node_idx);\n",
      "00499\t          long icount = PyInt_AsLong(count);\n",
      "00500\t          PyList_SetItem(self->call_counts, node_idx,\n",
      "00501\t                         PyInt_FromLong(icount + 1));\n",
      "00502\t      }\n",
      "00503\t    }\n",
      "00504\t  else\n",
      "00505\t    {\n",
      "00506\t      if (verbose)\n",
      "00507\t        {\n",
      "00508\t          fprintf(stderr, \"calling via Python (node %i)\\n\", (int)node_idx);\n",
      "00509\t        }\n",
      "00510\t      rval = PyObject_CallObject(thunk, NULL);\n",
      "00511\t    }\n",
      "00512\t  return rval;\n",
      "00513\t}\n",
      "00514\tstatic int c_call(CLazyLinker * self, Py_ssize_t node_idx, int verbose)\n",
      "00515\t{\n",
      "00516\t  void * ptr_addr = self->thunk_cptr_fn[node_idx];\n",
      "00517\t  int (*fn)(void*) = (int (*)(void*))(ptr_addr);\n",
      "00518\t  if (verbose) fprintf(stderr, \"calling non-lazy shortcut (node %i)\\n\", (int)node_idx);\n",
      "00519\t  int err = 0;\n",
      "00520\t  if (self->do_timing)\n",
      "00521\t    {\n",
      "00522\t      double t0 = pytime(NULL);\n",
      "00523\t      err = fn(self->thunk_cptr_data[node_idx]);\n",
      "00524\t      double t1 = pytime(NULL);\n",
      "00525\t      double ti = PyFloat_AsDouble(PyList_GetItem(self->call_times, node_idx));\n",
      "00526\t      PyList_SetItem(self->call_times, node_idx, PyFloat_FromDouble(t1 - t0 + ti));\n",
      "00527\t      PyObject * count = PyList_GetItem(self->call_counts, node_idx);\n",
      "00528\t      long icount = PyInt_AsLong(count);\n",
      "00529\t      PyList_SetItem(self->call_counts, node_idx, PyInt_FromLong(icount+1));\n",
      "00530\t    }\n",
      "00531\t  else\n",
      "00532\t    {\n",
      "00533\t      err = fn(self->thunk_cptr_data[node_idx]);\n",
      "00534\t    }\n",
      "00535\t\n",
      "00536\t  if (err)\n",
      "00537\t    {\n",
      "00538\t      // cast the argument to a PyList (as described near line 226 of cc.py)\n",
      "00539\t      PyObject * __ERROR = ((PyObject**)self->thunk_cptr_data[node_idx])[0];\n",
      "00540\t      assert (PyList_Check(__ERROR));\n",
      "00541\t      assert (PyList_Size(__ERROR) == 3);\n",
      "00542\t      PyObject * err_type = PyList_GetItem(__ERROR, 0); //stolen ref\n",
      "00543\t      PyObject * err_msg = PyList_GetItem(__ERROR, 1); //stolen ref\n",
      "00544\t      PyObject * err_trace = PyList_GetItem(__ERROR, 2); //stolen ref\n",
      "00545\t      PyList_SET_ITEM(__ERROR, 0, Py_None); Py_INCREF(Py_None); //clobbers old ref\n",
      "00546\t      PyList_SET_ITEM(__ERROR, 1, Py_None); Py_INCREF(Py_None); //clobbers old ref\n",
      "00547\t      PyList_SET_ITEM(__ERROR, 2, Py_None); Py_INCREF(Py_None); //clobbers old ref\n",
      "00548\t\n",
      "00549\t      assert(!PyErr_Occurred()); // because CLinker hid the exception in __ERROR aka data\n",
      "00550\t      PyErr_Restore(err_type, err_msg, err_trace); //steals refs to args\n",
      "00551\t    }\n",
      "00552\t  if (err) set_position_of_error(self, node_idx);\n",
      "00553\t  return err;\n",
      "00554\t}\n",
      "00555\tstatic\n",
      "00556\tint lazy_rec_eval(CLazyLinker * self, Py_ssize_t var_idx, PyObject*one, PyObject*zero)\n",
      "00557\t{\n",
      "00558\t  PyObject *rval = NULL;\n",
      "00559\t  int verbose = 0;\n",
      "00560\t  int err = 0;\n",
      "00561\t\n",
      "00562\t  if (verbose) fprintf(stderr, \"lazy_rec computing %i\\n\", (int)var_idx);\n",
      "00563\t\n",
      "00564\t  if (self->var_computed[var_idx] || !self->var_has_owner[var_idx])\n",
      "00565\t    return 0;\n",
      "00566\t\n",
      "00567\t  Py_ssize_t owner_idx = self->var_owner[var_idx];\n",
      "00568\t\n",
      "00569\t  // STEP 1: compute the pre-requirements of the node\n",
      "00570\t  // Includes input nodes for non-lazy ops.\n",
      "00571\t  for (int i = 0; i < self->node_n_prereqs[owner_idx]; ++i)\n",
      "00572\t    {\n",
      "00573\t      Py_ssize_t prereq_idx = self->node_prereqs[owner_idx][i];\n",
      "00574\t      if (!self->var_computed[prereq_idx])\n",
      "00575\t        {\n",
      "00576\t          err = lazy_rec_eval(self, prereq_idx, one, zero);\n",
      "00577\t          if (err) return err;\n",
      "00578\t        }\n",
      "00579\t      assert (self->var_computed[prereq_idx]);\n",
      "00580\t    }\n",
      "00581\t\n",
      "00582\t  // STEP 2: compute the node itself\n",
      "00583\t  if (self->is_lazy[owner_idx])\n",
      "00584\t    {\n",
      "00585\t      // update the compute_map cells corresponding to the inputs of this thunk\n",
      "00586\t      for (int i = 0; i < self->node_n_inputs[owner_idx]; ++i)\n",
      "00587\t        {\n",
      "00588\t          int in_idx = self->node_inputs[owner_idx][i];\n",
      "00589\t          if (self->var_computed[in_idx])\n",
      "00590\t            {\n",
      "00591\t              Py_INCREF(one);\n",
      "00592\t              err = PyList_SetItem(self->var_computed_cells[in_idx], 0, one);\n",
      "00593\t            }\n",
      "00594\t          else\n",
      "00595\t            {\n",
      "00596\t              Py_INCREF(zero);\n",
      "00597\t              err = PyList_SetItem(self->var_computed_cells[in_idx], 0, zero);\n",
      "00598\t            }\n",
      "00599\t          if (err) goto fail;\n",
      "00600\t        }\n",
      "00601\t\n",
      "00602\t      rval = pycall(self, owner_idx, verbose);\n",
      "00603\t      // refcounting - rval is new ref\n",
      "00604\t      //TODO: to prevent infinite loops\n",
      "00605\t      // - consider check that a thunk does not ask for an input that is already computed\n",
      "00606\t      if (rval == NULL)\n",
      "00607\t        {\n",
      "00608\t          assert (PyErr_Occurred());\n",
      "00609\t          err = 1;\n",
      "00610\t          goto fail;\n",
      "00611\t        }\n",
      "00612\t\n",
      "00613\t      //update the computed-ness of any output cells\n",
      "00614\t      for (int i = 0; i < self->node_n_outputs[owner_idx]; ++i)\n",
      "00615\t        {\n",
      "00616\t          int out_idx = self->node_outputs[owner_idx][i];\n",
      "00617\t          PyObject * el_i = PyList_GetItem(self->var_computed_cells[out_idx], 0);\n",
      "00618\t          Py_ssize_t N = PyNumber_AsSsize_t(el_i, PyExc_IndexError);\n",
      "00619\t          if (PyErr_Occurred())\n",
      "00620\t            {\n",
      "00621\t              err = -1;\n",
      "00622\t              goto pyfail;\n",
      "00623\t            }\n",
      "00624\t          assert (N==0 || N==1);\n",
      "00625\t          self->var_computed[out_idx] = N;\n",
      "00626\t        }\n",
      "00627\t      if (!self->var_computed[var_idx])\n",
      "00628\t        {\n",
      "00629\t          /*\n",
      "00630\t           * If self is not computed after the call, this means that some\n",
      "00631\t           * inputs are needed.  Compute the ones on the returned list\n",
      "00632\t           * and try to compute the current node again (with recursive call).\n",
      "00633\t           * This allows a node to request more nodes more than once before\n",
      "00634\t           * finally yielding a result.\n",
      "00635\t           */\n",
      "00636\t          if (!PyList_Check(rval))\n",
      "00637\t            {\n",
      "00638\t              //TODO: More helpful error to help find *which node* made this\n",
      "00639\t              // bad thunk\n",
      "00640\t              PyErr_SetString(PyExc_TypeError,\n",
      "00641\t                              \"lazy thunk should return a list\");\n",
      "00642\t              err = 1;\n",
      "00643\t              goto pyfail;\n",
      "00644\t            }\n",
      "00645\t\n",
      "00646\t          if (!PyList_Size(rval))\n",
      "00647\t            {\n",
      "00648\t              PyErr_SetString(PyExc_ValueError,\n",
      "00649\t                              \"lazy thunk returned empty list without computing output\");\n",
      "00650\t              err = 1;\n",
      "00651\t              goto pyfail;\n",
      "00652\t            }\n",
      "00653\t\n",
      "00654\t          for (int i = 0; i < PyList_Size(rval); ++i)\n",
      "00655\t            {\n",
      "00656\t              PyObject * el_i = PyList_GetItem(rval, i);\n",
      "00657\t              Py_ssize_t N = PyNumber_AsSsize_t(el_i, PyExc_IndexError);\n",
      "00658\t              if (PyErr_Occurred())\n",
      "00659\t                {\n",
      "00660\t                  err = 1;\n",
      "00661\t                  goto pyfail;\n",
      "00662\t                }\n",
      "00663\t              assert (N <= self->node_n_inputs[owner_idx]);\n",
      "00664\t              Py_ssize_t input_idx = self->node_inputs[owner_idx][N];\n",
      "00665\t              err = lazy_rec_eval(self, input_idx, one, zero);\n",
      "00666\t              if (err) goto pyfail;\n",
      "00667\t            }\n",
      "00668\t\n",
      "00669\t          Py_DECREF(rval);\n",
      "00670\t          /*\n",
      "00671\t           * We intentionally skip all the end-of-function processing\n",
      "00672\t           * (mark outputs, GC) as it will be performed by the call\n",
      "00673\t           * that actually manages to compute the result.\n",
      "00674\t           */\n",
      "00675\t          return lazy_rec_eval(self, var_idx, one, zero);\n",
      "00676\t        }\n",
      "00677\t\n",
      "00678\t      Py_DECREF(rval);\n",
      "00679\t    }\n",
      "00680\t  else //owner is not a lazy op. Ensure all intputs are evaluated.\n",
      "00681\t    {\n",
      "00682\t      // loop over inputs to owner\n",
      "00683\t      // call lazy_rec_eval on each one that is not computed.\n",
      "00684\t      // if there's an error, pass it up the stack\n",
      "00685\t      for (int i = 0; i < self->node_n_inputs[owner_idx]; ++i)\n",
      "00686\t        {\n",
      "00687\t          Py_ssize_t input_idx = self->node_inputs[owner_idx][i];\n",
      "00688\t          if (!self->var_computed[input_idx])\n",
      "00689\t            {\n",
      "00690\t              err = lazy_rec_eval(self, input_idx, one, zero);\n",
      "00691\t              if (err) return err;\n",
      "00692\t            }\n",
      "00693\t          assert (self->var_computed[input_idx]);\n",
      "00694\t        }\n",
      "00695\t\n",
      "00696\t      // call the thunk for this owner.\n",
      "00697\t      if (self->thunk_cptr_fn[owner_idx])\n",
      "00698\t        {\n",
      "00699\t          err = c_call(self, owner_idx, verbose);\n",
      "00700\t          if (err) goto fail;\n",
      "00701\t        }\n",
      "00702\t      else\n",
      "00703\t        {\n",
      "00704\t          rval = pycall(self, owner_idx, verbose);\n",
      "00705\t          //rval is new ref\n",
      "00706\t          if (rval) //pycall returned normally (no exception)\n",
      "00707\t            {\n",
      "00708\t              if (rval == Py_None)\n",
      "00709\t                {\n",
      "00710\t                  Py_DECREF(rval); //ignore a return of None\n",
      "00711\t                }\n",
      "00712\t              else if (PyList_Check(rval))\n",
      "00713\t                {\n",
      "00714\t                  PyErr_SetString(PyExc_TypeError,\n",
      "00715\t                                  \"non-lazy thunk should return None, not list\");\n",
      "00716\t                  err = 1;\n",
      "00717\t                  goto pyfail;\n",
      "00718\t                }\n",
      "00719\t              else // don't know what it returned, but it wasn't right.\n",
      "00720\t                {\n",
      "00721\t                  PyErr_SetObject(PyExc_TypeError, rval);\n",
      "00722\t                  err = 1;\n",
      "00723\t                  // We don't release rval since we put it in the error above\n",
      "00724\t                  goto fail;\n",
      "00725\t                }\n",
      "00726\t            }\n",
      "00727\t          else // pycall returned NULL (internal error)\n",
      "00728\t            {\n",
      "00729\t              err = 1;\n",
      "00730\t              goto fail;\n",
      "00731\t            }\n",
      "00732\t        }\n",
      "00733\t    }\n",
      "00734\t\n",
      "00735\t  // loop over all outputs and mark them as computed\n",
      "00736\t  for (int i = 0; i < self->node_n_outputs[owner_idx]; ++i)\n",
      "00737\t    {\n",
      "00738\t      self->var_computed[self->node_outputs[owner_idx][i]] = 1;\n",
      "00739\t    }\n",
      "00740\t\n",
      "00741\t  // Free vars that are not needed anymore\n",
      "00742\t  if (self->allow_gc)\n",
      "00743\t    {\n",
      "00744\t      for (int i = 0; i < self->node_n_inputs[owner_idx]; ++i)\n",
      "00745\t        {\n",
      "00746\t          int cleanup = 1;\n",
      "00747\t          Py_ssize_t i_idx = self->node_inputs[owner_idx][i];\n",
      "00748\t          if (!self->var_has_owner[i_idx])\n",
      "00749\t            continue;\n",
      "00750\t\n",
      "00751\t          for (int j = 0; j < self->n_output_vars; ++j)\n",
      "00752\t            {\n",
      "00753\t              if (i_idx == self->output_vars[j])\n",
      "00754\t                {\n",
      "00755\t                  cleanup = 0;\n",
      "00756\t                  break;\n",
      "00757\t                }\n",
      "00758\t            }\n",
      "00759\t          if (!cleanup) continue;\n",
      "00760\t\n",
      "00761\t          for (int j = 0; j < self->n_dependencies[i_idx]; ++j)\n",
      "00762\t            {\n",
      "00763\t              if (!self->var_computed[self->dependencies[i_idx][j]])\n",
      "00764\t                {\n",
      "00765\t                  cleanup = 0;\n",
      "00766\t                  break;\n",
      "00767\t                }\n",
      "00768\t            }\n",
      "00769\t          if (!cleanup) continue;\n",
      "00770\t\n",
      "00771\t          Py_INCREF(Py_None);\n",
      "00772\t          err = PyList_SetItem(self->var_value_cells[i_idx], 0, Py_None);\n",
      "00773\t//See the Stack gc implementation for why we change it to 2 and not 0.\n",
      "00774\t          self->var_computed[i_idx] = 2;\n",
      "00775\t          if (err) goto fail;\n",
      "00776\t        }\n",
      "00777\t    }\n",
      "00778\t\n",
      "00779\t  return 0;\n",
      "00780\t pyfail:\n",
      "00781\t  Py_DECREF(rval);\n",
      "00782\t fail:\n",
      "00783\t  set_position_of_error(self, owner_idx);\n",
      "00784\t  return err;\n",
      "00785\t}\n",
      "00786\t\n",
      "00787\tstatic PyObject *\n",
      "00788\tCLazyLinker_call(PyObject *_self, PyObject *args, PyObject *kwds)\n",
      "00789\t{\n",
      "00790\t  CLazyLinker * self = (CLazyLinker*)_self;\n",
      "00791\t  static char *kwlist[] = {\n",
      "00792\t    (char *)\"time_thunks\",\n",
      "00793\t    (char *)\"n_calls\",\n",
      "00794\t    (char *)\"output_subset\",\n",
      "00795\t    NULL};\n",
      "00796\t  int n_calls=1;\n",
      "00797\t  PyObject *output_subset_ptr = NULL;\n",
      "00798\t  if (! PyArg_ParseTupleAndKeywords(args, kwds, \"|iiO\", kwlist,\n",
      "00799\t                                    &self->do_timing,\n",
      "00800\t                                    &n_calls,\n",
      "00801\t                                    &output_subset_ptr))\n",
      "00802\t    return NULL;\n",
      "00803\t\n",
      "00804\t  int err = 0;\n",
      "00805\t  // parse an output_subset list\n",
      "00806\t  // it is stored as a bool list of length n_output_vars: calculate a var or not\n",
      "00807\t  char *output_subset = NULL;\n",
      "00808\t  int output_subset_size = -1;\n",
      "00809\t  if (output_subset_ptr != NULL)\n",
      "00810\t    {\n",
      "00811\t      if (! PyList_Check(output_subset_ptr))\n",
      "00812\t        {\n",
      "00813\t          err = 1;\n",
      "00814\t          PyErr_SetString(PyExc_RuntimeError, \"Output_subset is not a list\");\n",
      "00815\t        }\n",
      "00816\t      else\n",
      "00817\t        {\n",
      "00818\t          output_subset_size = PyList_Size(output_subset_ptr);\n",
      "00819\t          output_subset = (char*)calloc(self->n_output_vars, sizeof(char));\n",
      "00820\t          for (int it = 0; it < output_subset_size; ++it)\n",
      "00821\t            {\n",
      "00822\t              PyObject *elem = PyList_GetItem(output_subset_ptr, it);\n",
      "00823\t              if (! PyInt_Check(elem))\n",
      "00824\t                {\n",
      "00825\t                  err = 1;\n",
      "00826\t                  PyErr_SetString(PyExc_RuntimeError, \"Some elements of output_subset list are not int\");\n",
      "00827\t                }\n",
      "00828\t              output_subset[PyInt_AsLong(elem)] = 1;\n",
      "00829\t            }\n",
      "00830\t        }\n",
      "00831\t    }\n",
      "00832\t\n",
      "00833\t  self->position_of_error = -1;\n",
      "00834\t  // create constants used to fill the var_compute_cells\n",
      "00835\t  PyObject * one = PyInt_FromLong(1);\n",
      "00836\t  PyObject * zero = PyInt_FromLong(0);\n",
      "00837\t\n",
      "00838\t  // pre-allocate our return value\n",
      "00839\t  Py_INCREF(Py_None);\n",
      "00840\t  PyObject * rval = Py_None;\n",
      "00841\t  //clear storage of pre_call_clear elements\n",
      "00842\t  for (int call_i = 0; call_i < n_calls && (!err); ++call_i)\n",
      "00843\t    {\n",
      "00844\t      Py_ssize_t n_pre_call_clear = PyList_Size(self->pre_call_clear);\n",
      "00845\t      assert(PyList_Check(self->pre_call_clear));\n",
      "00846\t      for (int i = 0; i < n_pre_call_clear; ++i)\n",
      "00847\t        {\n",
      "00848\t          PyObject * el_i = PyList_GetItem(self->pre_call_clear, i);\n",
      "00849\t          Py_INCREF(Py_None);\n",
      "00850\t          PyList_SetItem(el_i, 0, Py_None);\n",
      "00851\t        }\n",
      "00852\t      //clear the computed flag out of all non-input vars\n",
      "00853\t      for (int i = 0; i < self->n_vars; ++i)\n",
      "00854\t        {\n",
      "00855\t          self->var_computed[i] = !self->var_has_owner[i];\n",
      "00856\t          if (self->var_computed[i])\n",
      "00857\t            {\n",
      "00858\t              Py_INCREF(one);\n",
      "00859\t              PyList_SetItem(self->var_computed_cells[i], 0, one);\n",
      "00860\t            }\n",
      "00861\t          else\n",
      "00862\t            {\n",
      "00863\t              Py_INCREF(zero);\n",
      "00864\t              PyList_SetItem(self->var_computed_cells[i], 0, zero);\n",
      "00865\t            }\n",
      "00866\t        }\n",
      "00867\t\n",
      "00868\t      int first_updated = self->n_output_vars - self->n_updates;\n",
      "00869\t      for (int i = 0; i < self->n_output_vars && (!err); ++i)\n",
      "00870\t        {\n",
      "00871\t          if (i >= first_updated || output_subset == NULL || output_subset[i] == 1)\n",
      "00872\t            {\n",
      "00873\t              err = lazy_rec_eval(self, self->output_vars[i], one, zero);\n",
      "00874\t            }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `_import_array':\r\n",
      "C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1460: undefined reference to `__imp_PyExc_ImportError'\r\n",
      "C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1466: undefined reference to `__imp_PyExc_AttributeError'\r\n",
      "C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1471: undefined reference to `__imp_PyCapsule_Type'\r\n",
      "C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1472: undefined reference to `__imp_PyExc_RuntimeError'\r\n",
      "C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1487: undefined reference to `__imp_PyExc_RuntimeError'\r\n",
      "C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1495: undefined reference to `__imp_PyExc_RuntimeError'\r\n",
      "C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1501: undefined reference to `__imp_PyExc_RuntimeError'\r\n",
      "C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1511: undefined reference to `__imp_PyExc_RuntimeError'\r\n",
      "C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o:C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1523: more undefined references to `__imp_PyExc_RuntimeError' follow\r\n",
      "C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `NpyCapsule_Check':\r\n",
      "C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/npy_3kcompat.h:456: undefined reference to `__imp_PyCapsule_Type'\r\n",
      "C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `unpack_list_of_ssize_t':\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:48: undefined reference to `__imp_PyExc_TypeError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:58: undefined reference to `__imp_PyExc_IndexError'\r\n",
      "C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_init':\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:352: undefined reference to `__imp_PyExc_IndexError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:370: undefined reference to `__imp_PyExc_IndexError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:385: undefined reference to `__imp_PyExc_IndexError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:389: undefined reference to `__imp_PyExc_IndexError'\r\n",
      "C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o:C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:393: more undefined references to `__imp_PyExc_IndexError' follow\r\n",
      "C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_init':\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:405: undefined reference to `__imp_PyExc_TypeError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:420: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:426: undefined reference to `__imp_PyExc_IndexError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:440: undefined reference to `__imp_PyExc_TypeError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:444: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `c_call':\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:545: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:545: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:545: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:546: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o:C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:546: more undefined references to `__imp__Py_NoneStruct' follow\r\n",
      "C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `lazy_rec_eval':\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:618: undefined reference to `__imp_PyExc_IndexError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:641: undefined reference to `__imp_PyExc_TypeError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:649: undefined reference to `__imp_PyExc_ValueError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:657: undefined reference to `__imp_PyExc_IndexError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:708: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:715: undefined reference to `__imp_PyExc_TypeError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:721: undefined reference to `__imp_PyExc_TypeError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:771: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:771: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:772: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_call':\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:814: undefined reference to `__imp_PyExc_RuntimeError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:826: undefined reference to `__imp_PyExc_RuntimeError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:839: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:839: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:840: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:849: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:849: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o:C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:850: more undefined references to `__imp__Py_NoneStruct' follow\r\n",
      "C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_call':\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:894: undefined reference to `__imp_PyExc_AssertionError'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:937: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:937: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:938: undefined reference to `__imp__Py_NoneStruct'\r\n",
      "C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_set_allow_gc':\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:973: undefined reference to `__imp_PyBool_Type'\r\n",
      "C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:976: undefined reference to `__imp__Py_TrueStruct'\r\n",
      "collect2.exe: error: ld returned 1 exit status\r\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00875\t        }\n",
      "00876\t\n",
      "00877\t      if (!err)\n",
      "00878\t        {\n",
      "00879\t          // save references to outputs prior to updating storage containers\n",
      "00880\t          assert (self->n_output_vars >= self->n_updates);\n",
      "00881\t          Py_DECREF(rval);\n",
      "00882\t          rval = PyList_New(self->n_output_vars);\n",
      "00883\t          for (int i = 0; i < (self->n_output_vars); ++i)\n",
      "00884\t            {\n",
      "00885\t              Py_ssize_t src = self->output_vars[i];\n",
      "00886\t              PyObject * item = PyList_GetItem(self->var_value_cells[src], 0);\n",
      "00887\t              if ((output_subset == NULL || output_subset[i]) &&\n",
      "00888\t                  self->var_computed[src] != 1)\n",
      "00889\t                {\n",
      "00890\t                  err = 1;\n",
      "00891\t                  PyErr_Format(PyExc_AssertionError,\n",
      "00892\t                               \"The compute map of output %d should contain \"\n",
      "00893\t                               \"1 at the end of execution, not %d.\",\n",
      "00894\t                               i, self->var_computed[src]);\n",
      "00895\t                  break;\n",
      "00896\t                }\n",
      "00897\t              Py_INCREF(item);\n",
      "00898\t              PyList_SetItem(rval, i, item);\n",
      "00899\t            }\n",
      "00900\t        }\n",
      "00901\t\n",
      "00902\t      if (!err)\n",
      "00903\t        {\n",
      "00904\t          // Update the inputs that have an update rule\n",
      "00905\t          for (int i = 0; i < self->n_updates; ++i)\n",
      "00906\t            {\n",
      "00907\t              PyObject* tmp = PyList_GetItem(rval, self->n_output_vars - self->n_updates + i);\n",
      "00908\t              Py_INCREF(tmp);\n",
      "00909\t              Py_ssize_t dst = self->update_storage[i];\n",
      "00910\t              PyList_SetItem(self->var_value_cells[dst], 0, tmp);\n",
      "00911\t            }\n",
      "00912\t        }\n",
      "00913\t    }\n",
      "00914\t\n",
      "00915\t  /*\n",
      "00916\t    Clear everything that is left and not an output. This is needed\n",
      "00917\t    for lazy evaluation since the current GC algo is too conservative\n",
      "00918\t    with lazy graphs.\n",
      "00919\t  */\n",
      "00920\t  if (self->allow_gc && !err)\n",
      "00921\t    {\n",
      "00922\t      for (Py_ssize_t i = 0; i < self->n_vars; ++i)\n",
      "00923\t        {\n",
      "00924\t          int do_cleanup = 1;\n",
      "00925\t          if (!self->var_has_owner[i] || !self->var_computed[i])\n",
      "00926\t            continue;\n",
      "00927\t          for (int j = 0; j < self->n_output_vars; ++j)\n",
      "00928\t            {\n",
      "00929\t              if (i == self->output_vars[j])\n",
      "00930\t                {\n",
      "00931\t                  do_cleanup = 0;\n",
      "00932\t                  break;\n",
      "00933\t                }\n",
      "00934\t            }\n",
      "00935\t          if (!do_cleanup)\n",
      "00936\t            continue;\n",
      "00937\t          Py_INCREF(Py_None);\n",
      "00938\t          PyList_SetItem(self->var_value_cells[i], 0, Py_None);\n",
      "00939\t        }\n",
      "00940\t    }\n",
      "00941\t  if (output_subset != NULL)\n",
      "00942\t    free(output_subset);\n",
      "00943\t\n",
      "00944\t  Py_DECREF(one);\n",
      "00945\t  Py_DECREF(zero);\n",
      "00946\t  if (err)\n",
      "00947\t    {\n",
      "00948\t      Py_DECREF(rval);\n",
      "00949\t      return NULL;\n",
      "00950\t    }\n",
      "00951\t  return rval;\n",
      "00952\t}\n",
      "00953\t\n",
      "00954\t#if 0\n",
      "00955\tstatic PyMethodDef CLazyLinker_methods[] = {\n",
      "00956\t    {\n",
      "00957\t      //\"name\", (PyCFunction)CLazyLinker_accept, METH_VARARGS, \"Return the name, combining the first and last name\"\n",
      "00958\t    },\n",
      "00959\t    {NULL}  /* Sentinel */\n",
      "00960\t};\n",
      "00961\t#endif\n",
      "00962\t\n",
      "00963\t\n",
      "00964\tstatic PyObject *\n",
      "00965\tCLazyLinker_get_allow_gc(CLazyLinker *self, void *closure)\n",
      "00966\t{\n",
      "00967\t    return PyBool_FromLong(self->allow_gc);\n",
      "00968\t}\n",
      "00969\t\n",
      "00970\tstatic int\n",
      "00971\tCLazyLinker_set_allow_gc(CLazyLinker *self, PyObject *value, void *closure)\n",
      "00972\t{\n",
      "00973\t  if(!PyBool_Check(value))\n",
      "00974\t    return -1;\n",
      "00975\t\n",
      "00976\t  if (value == Py_True)\n",
      "00977\t    self->allow_gc = true;\n",
      "00978\t  else\n",
      "00979\t    self->allow_gc = false;\n",
      "00980\t  return 0;\n",
      "00981\t}\n",
      "00982\t\n",
      "00983\tstatic PyGetSetDef CLazyLinker_getset[] = {\n",
      "00984\t  {(char*)\"allow_gc\",\n",
      "00985\t   (getter)CLazyLinker_get_allow_gc,\n",
      "00986\t   (setter)CLazyLinker_set_allow_gc,\n",
      "00987\t   (char*)\"do this function support allow_gc\",\n",
      "00988\t   NULL},\n",
      "00989\t  {NULL, NULL, NULL, NULL}  /* Sentinel */\n",
      "00990\t};\n",
      "00991\tstatic PyMemberDef CLazyLinker_members[] = {\n",
      "00992\t    {(char*)\"nodes\", T_OBJECT_EX, offsetof(CLazyLinker, nodes), 0,\n",
      "00993\t     (char*)\"list of nodes\"},\n",
      "00994\t    {(char*)\"thunks\", T_OBJECT_EX, offsetof(CLazyLinker, thunks), 0,\n",
      "00995\t     (char*)\"list of thunks in program\"},\n",
      "00996\t    {(char*)\"call_counts\", T_OBJECT_EX, offsetof(CLazyLinker, call_counts), 0,\n",
      "00997\t     (char*)\"number of calls of each thunk\"},\n",
      "00998\t    {(char*)\"call_times\", T_OBJECT_EX, offsetof(CLazyLinker, call_times), 0,\n",
      "00999\t     (char*)\"total runtime in each thunk\"},\n",
      "01000\t    {(char*)\"position_of_error\", T_INT, offsetof(CLazyLinker, position_of_error), 0,\n",
      "01001\t     (char*)\"position of failed thunk\"},\n",
      "01002\t    {(char*)\"time_thunks\", T_INT, offsetof(CLazyLinker, do_timing), 0,\n",
      "01003\t     (char*)\"bool: nonzero means call will time thunks\"},\n",
      "01004\t    {(char*)\"need_update_inputs\", T_INT, offsetof(CLazyLinker, need_update_inputs), 0,\n",
      "01005\t     (char*)\"bool: nonzero means Function.__call__ must implement update mechanism\"},\n",
      "01006\t    {NULL}  /* Sentinel */\n",
      "01007\t};\n",
      "01008\t\n",
      "01009\tstatic PyTypeObject lazylinker_ext_CLazyLinkerType = {\n",
      "01010\t#if defined(NPY_PY3K)\n",
      "01011\t    PyVarObject_HEAD_INIT(NULL, 0)\n",
      "01012\t#else\n",
      "01013\t    PyObject_HEAD_INIT(NULL)\n",
      "01014\t    0,                         /*ob_size*/\n",
      "01015\t#endif\n",
      "01016\t    \"lazylinker_ext.CLazyLinker\",             /*tp_name*/\n",
      "01017\t    sizeof(CLazyLinker), /*tp_basicsize*/\n",
      "01018\t    0,                         /*tp_itemsize*/\n",
      "01019\t    CLazyLinker_dealloc,       /*tp_dealloc*/\n",
      "01020\t    0,                         /*tp_print*/\n",
      "01021\t    0,                         /*tp_getattr*/\n",
      "01022\t    0,                         /*tp_setattr*/\n",
      "01023\t    0,                         /*tp_compare*/\n",
      "01024\t    0,                         /*tp_repr*/\n",
      "01025\t    0,                         /*tp_as_number*/\n",
      "01026\t    0,                         /*tp_as_sequence*/\n",
      "01027\t    0,                         /*tp_as_mapping*/\n",
      "01028\t    0,                         /*tp_hash */\n",
      "01029\t    CLazyLinker_call,          /*tp_call*/\n",
      "01030\t    0,                         /*tp_str*/\n",
      "01031\t    0,                         /*tp_getattro*/\n",
      "01032\t    0,                         /*tp_setattro*/\n",
      "01033\t    0,                         /*tp_as_buffer*/\n",
      "01034\t    Py_TPFLAGS_DEFAULT|Py_TPFLAGS_BASETYPE,        /*tp_flags*/\n",
      "01035\t    \"CLazyLinker object\",      /* tp_doc */\n",
      "01036\t    0,                         /* tp_traverse */\n",
      "01037\t    0,                         /* tp_clear */\n",
      "01038\t    0,                         /* tp_richcompare */\n",
      "01039\t    0,                         /* tp_weaklistoffset */\n",
      "01040\t    0,                         /* tp_iter */\n",
      "01041\t    0,                         /* tp_iternext */\n",
      "01042\t    0,//CLazyLinker_methods,       /* tp_methods */\n",
      "01043\t    CLazyLinker_members,       /* tp_members */\n",
      "01044\t    CLazyLinker_getset,        /* tp_getset */\n",
      "01045\t    0,                         /* tp_base */\n",
      "01046\t    0,                         /* tp_dict */\n",
      "01047\t    0,                         /* tp_descr_get */\n",
      "01048\t    0,                         /* tp_descr_set */\n",
      "01049\t    0,                         /* tp_dictoffset */\n",
      "01050\t    (initproc)CLazyLinker_init,/* tp_init */\n",
      "01051\t    0,                         /* tp_alloc */\n",
      "01052\t    CLazyLinker_new,           /* tp_new */\n",
      "01053\t};\n",
      "01054\t\n",
      "01055\tstatic PyObject * get_version(PyObject *dummy, PyObject *args)\n",
      "01056\t{\n",
      "01057\t  PyObject *result = PyFloat_FromDouble(0.211);\n",
      "01058\t  return result;\n",
      "01059\t}\n",
      "01060\t\n",
      "01061\tstatic PyMethodDef lazylinker_ext_methods[] = {\n",
      "01062\t  {\"get_version\",  get_version, METH_VARARGS, \"Get extension version.\"},\n",
      "01063\t  {NULL, NULL, 0, NULL}        /* Sentinel */\n",
      "01064\t};\n",
      "01065\t\n",
      "01066\t#if defined(NPY_PY3K)\n",
      "01067\tstatic struct PyModuleDef moduledef = {\n",
      "01068\t        PyModuleDef_HEAD_INIT,\n",
      "01069\t        \"lazylinker_ext\",\n",
      "01070\t        NULL,\n",
      "01071\t        -1,\n",
      "01072\t        lazylinker_ext_methods,\n",
      "01073\t        NULL,\n",
      "01074\t        NULL,\n",
      "01075\t        NULL,\n",
      "01076\t        NULL\n",
      "01077\t};\n",
      "01078\t#endif\n",
      "01079\t#if defined(NPY_PY3K)\n",
      "01080\t#define RETVAL m\n",
      "01081\tPyMODINIT_FUNC\n",
      "01082\tPyInit_lazylinker_ext(void) {\n",
      "01083\t#else\n",
      "01084\t#define RETVAL\n",
      "01085\tPyMODINIT_FUNC\n",
      "01086\tinitlazylinker_ext(void) \n",
      "01087\t{\n",
      "01088\t#endif\n",
      "01089\t    PyObject* m;\n",
      "01090\t\n",
      "01091\t    lazylinker_ext_CLazyLinkerType.tp_new = PyType_GenericNew;\n",
      "01092\t    if (PyType_Ready(&lazylinker_ext_CLazyLinkerType) < 0)\n",
      "01093\t        return RETVAL;\n",
      "01094\t#if defined(NPY_PY3K)\n",
      "01095\t    m = PyModule_Create(&moduledef);\n",
      "01096\t#else\n",
      "01097\t    m = Py_InitModule3(\"lazylinker_ext\", lazylinker_ext_methods,\n",
      "01098\t                       \"Example module that creates an extension type.\");\n",
      "01099\t#endif\n",
      "01100\t    Py_INCREF(&lazylinker_ext_CLazyLinkerType);\n",
      "01101\t    PyModule_AddObject(m, \"CLazyLinker\", (PyObject *)&lazylinker_ext_CLazyLinkerType);\n",
      "01102\t\n",
      "01103\t    return RETVAL;\n",
      "01104\t}\n",
      "01105\t\n",
      "Problem occurred during compilation with the command line below:\n",
      "\"C:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\Library\\mingw-w64\\bin\\g++.exe\" -shared -g -march=haswell -mmmx -mno-3dnow -msse -msse2 -msse3 -mssse3 -mno-sse4a -mcx16 -msahf -mmovbe -maes -mno-sha -mpclmul -mpopcnt -mabm -mno-lwp -mfma -mno-fma4 -mno-xop -mbmi -mbmi2 -mno-tbm -mavx -mavx2 -msse4.2 -msse4.1 -mlzcnt -mno-rtm -mno-hle -mrdrnd -mf16c -mfsgsbase -mno-rdseed -mno-prfchw -mno-adx -mfxsr -mxsave -mxsaveopt -mno-avx512f -mno-avx512er -mno-avx512cd -mno-avx512pf -mno-prefetchwt1 -mno-clflushopt -mno-xsavec -mno-xsaves -mno-avx512dq -mno-avx512bw -mno-avx512vl -mno-avx512ifma -mno-avx512vbmi -mno-clwb -mno-pcommit -mno-mwaitx --param l1-cache-size=32 --param l1-cache-line-size=64 --param l2-cache-size=15360 -mtune=haswell -DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION -m64 -DMS_WIN64 -I\"C:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\lib\\site-packages\\numpy\\core\\include\" -I\"C:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\include\" -I\"C:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\lib\\site-packages\\theano\\gof\" -L\"C:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\libs\" -L\"C:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\" -o C:\\Users\\anlaursen\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64\\lazylinker_ext\\lazylinker_ext.pyd C:\\Users\\anlaursen\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64\\lazylinker_ext\\mod.cpp -lpython35\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Compilation failed (return status=1): C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `_import_array':\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1460: undefined reference to `__imp_PyExc_ImportError'\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1466: undefined reference to `__imp_PyExc_AttributeError'\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1471: undefined reference to `__imp_PyCapsule_Type'\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1472: undefined reference to `__imp_PyExc_RuntimeError'\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1487: undefined reference to `__imp_PyExc_RuntimeError'\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1495: undefined reference to `__imp_PyExc_RuntimeError'\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1501: undefined reference to `__imp_PyExc_RuntimeError'\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1511: undefined reference to `__imp_PyExc_RuntimeError'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o:C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1523: more undefined references to `__imp_PyExc_RuntimeError' follow\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `NpyCapsule_Check':\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/npy_3kcompat.h:456: undefined reference to `__imp_PyCapsule_Type'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `unpack_list_of_ssize_t':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:48: undefined reference to `__imp_PyExc_TypeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:58: undefined reference to `__imp_PyExc_IndexError'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_init':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:352: undefined reference to `__imp_PyExc_IndexError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:370: undefined reference to `__imp_PyExc_IndexError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:385: undefined reference to `__imp_PyExc_IndexError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:389: undefined reference to `__imp_PyExc_IndexError'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o:C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:393: more undefined references to `__imp_PyExc_IndexError' follow\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_init':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:405: undefined reference to `__imp_PyExc_TypeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:420: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:426: undefined reference to `__imp_PyExc_IndexError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:440: undefined reference to `__imp_PyExc_TypeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:444: undefined reference to `__imp__Py_NoneStruct'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `c_call':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:545: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:545: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:545: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:546: undefined reference to `__imp__Py_NoneStruct'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o:C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:546: more undefined references to `__imp__Py_NoneStruct' follow\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `lazy_rec_eval':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:618: undefined reference to `__imp_PyExc_IndexError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:641: undefined reference to `__imp_PyExc_TypeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:649: undefined reference to `__imp_PyExc_ValueError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:657: undefined reference to `__imp_PyExc_IndexError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:708: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:715: undefined reference to `__imp_PyExc_TypeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:721: undefined reference to `__imp_PyExc_TypeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:771: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:771: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:772: undefined reference to `__imp__Py_NoneStruct'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_call':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:814: undefined reference to `__imp_PyExc_RuntimeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:826: undefined reference to `__imp_PyExc_RuntimeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:839: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:839: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:840: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:849: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:849: undefined reference to `__imp__Py_NoneStruct'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o:C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:850: more undefined references to `__imp__Py_NoneStruct' follow\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_call':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:894: undefined reference to `__imp_PyExc_AssertionError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:937: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:937: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:938: undefined reference to `__imp__Py_NoneStruct'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_set_allow_gc':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:973: undefined reference to `__imp_PyBool_Type'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:976: undefined reference to `__imp__Py_TrueStruct'\r. collect2.exe: error: ld returned 1 exit status\r. ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\lib\\site-packages\\theano\\gof\\lazylinker_c.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlazylinker_ext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_version'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\lib\\site-packages\\theano\\gof\\lazylinker_c.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlazylinker_ext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_version'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3bc3c34eb859>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\lib\\site-packages\\theano\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m     object2, utils)\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m from theano.compile import (\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[0mSymbolicInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mSymbolicOutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOut\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\lib\\site-packages\\theano\\compile\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         SpecifyShape, specify_shape, register_specify_shape_c_code)\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_module\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mizip\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiling\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m from theano.compile.io import (\n",
      "\u001b[1;32mC:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\lib\\site-packages\\theano\\compile\\mode.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgof\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfigparser\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_output_guard\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcxx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lazylinker will not be imported if theano.config.cxx is not set.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlazylinker_c\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mCVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlazylinker_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLazyLinker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\lib\\site-packages\\theano\\gof\\lazylinker_c.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGCC_compiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             cmodule.GCC_compiler.compile_str(dirname, code, location=loc,\n\u001b[1;32m--> 127\u001b[1;33m                                              preargs=args)\n\u001b[0m\u001b[0;32m    128\u001b[0m             \u001b[1;31m# Save version into the __init__.py file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0minit_py\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__init__.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\anlaursen\\AppData\\Loca\\Anaconda3\\envs\\py3\\lib\\site-packages\\theano\\gof\\cmodule.py\u001b[0m in \u001b[0;36mcompile_str\u001b[1;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)\u001b[0m\n\u001b[0;32m   2314\u001b[0m             \u001b[1;31m# difficult to read.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2315\u001b[0m             raise Exception('Compilation failed (return status=%s): %s' %\n\u001b[1;32m-> 2316\u001b[1;33m                             (status, compile_stderr.replace('\\n', '. ')))\n\u001b[0m\u001b[0;32m   2317\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompilation_warning\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcompile_stderr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2318\u001b[0m             \u001b[1;31m# Print errors just below the command line.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Compilation failed (return status=1): C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `_import_array':\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1460: undefined reference to `__imp_PyExc_ImportError'\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1466: undefined reference to `__imp_PyExc_AttributeError'\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1471: undefined reference to `__imp_PyCapsule_Type'\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1472: undefined reference to `__imp_PyExc_RuntimeError'\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1487: undefined reference to `__imp_PyExc_RuntimeError'\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1495: undefined reference to `__imp_PyExc_RuntimeError'\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1501: undefined reference to `__imp_PyExc_RuntimeError'\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1511: undefined reference to `__imp_PyExc_RuntimeError'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o:C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1523: more undefined references to `__imp_PyExc_RuntimeError' follow\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `NpyCapsule_Check':\r. C:/Users/anlaursen/AppData/Loca/Anaconda3/envs/py3/lib/site-packages/numpy/core/include/numpy/npy_3kcompat.h:456: undefined reference to `__imp_PyCapsule_Type'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `unpack_list_of_ssize_t':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:48: undefined reference to `__imp_PyExc_TypeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:58: undefined reference to `__imp_PyExc_IndexError'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_init':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:352: undefined reference to `__imp_PyExc_IndexError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:370: undefined reference to `__imp_PyExc_IndexError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:385: undefined reference to `__imp_PyExc_IndexError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:389: undefined reference to `__imp_PyExc_IndexError'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o:C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:393: more undefined references to `__imp_PyExc_IndexError' follow\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_init':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:405: undefined reference to `__imp_PyExc_TypeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:420: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:426: undefined reference to `__imp_PyExc_IndexError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:440: undefined reference to `__imp_PyExc_TypeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:444: undefined reference to `__imp__Py_NoneStruct'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `c_call':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:545: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:545: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:545: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:546: undefined reference to `__imp__Py_NoneStruct'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o:C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:546: more undefined references to `__imp__Py_NoneStruct' follow\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `lazy_rec_eval':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:618: undefined reference to `__imp_PyExc_IndexError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:641: undefined reference to `__imp_PyExc_TypeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:649: undefined reference to `__imp_PyExc_ValueError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:657: undefined reference to `__imp_PyExc_IndexError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:708: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:715: undefined reference to `__imp_PyExc_TypeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:721: undefined reference to `__imp_PyExc_TypeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:771: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:771: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:772: undefined reference to `__imp__Py_NoneStruct'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_call':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:814: undefined reference to `__imp_PyExc_RuntimeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:826: undefined reference to `__imp_PyExc_RuntimeError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:839: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:839: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:840: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:849: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:849: undefined reference to `__imp__Py_NoneStruct'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o:C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:850: more undefined references to `__imp__Py_NoneStruct' follow\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_call':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:894: undefined reference to `__imp_PyExc_AssertionError'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:937: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:937: undefined reference to `__imp__Py_NoneStruct'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:938: undefined reference to `__imp__Py_NoneStruct'\r. C:\\Users\\ANLAUR~1\\AppData\\Local\\Temp\\5\\ccjBnrjh.o: In function `CLazyLinker_set_allow_gc':\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:973: undefined reference to `__imp_PyBool_Type'\r. C:/Users/anlaursen/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.5.3-64/lazylinker_ext/mod.cpp:976: undefined reference to `__imp__Py_TrueStruct'\r. collect2.exe: error: ld returned 1 exit status\r. "
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import shared, tensor as T\n",
    "from theano.tensor.nnet import nnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_input = vocab_size\n",
    "n_output = vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using raw theano, we have to create our weight matrices and bias vectors ourselves - here are the functions we'll use to do so (using glorot initialization).\n",
    "The return values are wrapped in shared(), which is how we tell theano that it can manage this data (copying it to and from the GPU as necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def init_wgts(rows, cols):\n",
    "    # Initialise weights with random numbers of given scale.\n",
    "    \n",
    "    # Calculate the scale of the random numbers\n",
    "    scale = math.sqrt(2 / rows)\n",
    "    \n",
    "    # Create the random numbers from normal distribution. We use shared as wrapper\n",
    "    # to pass it to Theano for later use in the GPU calculations.\n",
    "    return shared(normal(scale = scale, size = (rows, cols)).astype(np.float32))\n",
    "\n",
    "def init_bias(rows):\n",
    "    # Intialise bias by using a simple 0 vector. We use shared as wrapper\n",
    "    # to pass it to Theano for later use in the GPU calculations.\n",
    "    \n",
    "    return shared(np.zeros(rows, dtype = np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We return the weights and biases together as a tuple. For the hidden weights, we'll use an identity initialization (as recommended by [Hinton](https://arxiv.org/abs/1504.00941).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def wgts_and_bias(n_in, n_out):\n",
    "    # Generate weights and bias for input and output layers\n",
    "    \n",
    "    # n_in rows and n_out columns\n",
    "    return init_wgts(n_in, n_out), init_bias(n_out)\n",
    "\n",
    "def id_and_bias(n):\n",
    "    # Generate weights and bias for hidden layers layers\n",
    "    \n",
    "    # Use identity matrix as initialisation as proposed by Hinton.\n",
    "    return shared(np.eye(n, dtype = np.float32)), init_bias(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Theano doesn't actually do any computations until we explicitly compile and evaluate the function (at which point it'll be turned into CUDA code and sent off to the GPU). So our job is to describe the computations that we'll want theano to do - the first step is to tell theano what inputs we'll be providing to our computation. So we construct some input and output tensors in the form of matrixes, vectors and scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Specify variables.\n",
    "t_inp = T.matrix('inp')\n",
    "t_outp = T.matrix('outp')\n",
    "t_h0 = T.vector('h0')\n",
    "lr = T.scalar('lr')\n",
    "\n",
    "all_args = [t_h0, t_inp, t_outp, lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we're ready to create our intial weight matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Weights and bias to hidden layer\n",
    "W_h = id_and_bias(n_hidden)\n",
    "\n",
    "# Weights and bias to input\n",
    "W_x = wgts_and_bias(n_input, n_hidden)\n",
    "\n",
    "# Weights and bias to output\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "\n",
    "# Gather in a single list\n",
    "w_all = list(chain.from_iterable([W_h, W_x, W_y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Theano handles looping (in this case looping trough our RNN) by using the [GPU scan](http://http.developer.nvidia.com/GPUGems3/gpugems3_ch39.html) operation. We have to tell theano what to do at each step through the scan - this is the function we'll use, which does a single forward pass for one character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W_h, b_h, W_x, b_x, W_y, b_y):\n",
    "    \n",
    "    # Calculate the hidden activations\n",
    "    h = nnet.relu(T.dot(x, W_x) + b_x + T.dot(h, W_h) + b_h)\n",
    "    \n",
    "    # Calculate the output activations\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    \n",
    "    # Return both (the 'Flatten()' is to work around a theano bug)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can provide everything necessary for the scan operation, so we can setup that up - we have to pass in the function to call at each step, the sequence to step through, the initial values of the outputs, and any other arguments to pass to the step function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Perform one function for every sequence\n",
    "[v_h, v_y], _ = theano.scan(step,\n",
    "                            sequences = t_inp, \n",
    "                            outputs_info = [t_h0, None],\n",
    "                            non_sequences = w_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can now calculate our loss function, and all of our gradients, with just a couple of lines of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We even have to show theano how to do SGD - so we set up this dictionary of updates to complete after every forward pass, which apply to standard SGD update rule to every weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def upd_dict(wgts, grads, lr): \n",
    "    return OrderedDict({w: w - g * lr for (w, g) in zip(wgts, grads)})\n",
    "\n",
    "upd = upd_dict(w_all, g_all, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're finally ready to compile the function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fn = theano.function(all_args, error, updates = upd, allow_input_downcast = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can then specify the actual values for the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75110, 8, 86), (75110, 8, 86))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = oh_x_rnn\n",
    "Y = oh_y_rnn\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To use it, we simply loop through our input data, calling the function compiled above, and printing our progress from time to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:25.154\n",
      "Error:21.470\n",
      "Error:20.950\n",
      "Error:19.943\n",
      "Error:18.830\n",
      "Error:19.258\n",
      "Error:19.059\n",
      "Error:18.418\n",
      "Error:17.941\n",
      "Error:18.256\n",
      "Error:17.512\n",
      "Error:17.630\n",
      "Error:18.476\n",
      "Error:17.351\n",
      "Error:16.812\n",
      "Error:17.733\n",
      "Error:17.370\n",
      "Error:17.227\n",
      "Error:16.858\n",
      "Error:16.707\n",
      "Error:16.542\n",
      "Error:16.401\n",
      "Error:16.709\n",
      "Error:16.189\n",
      "Error:16.872\n",
      "Error:16.627\n",
      "Error:16.081\n",
      "Error:16.308\n",
      "Error:16.277\n",
      "Error:16.445\n",
      "Error:16.746\n",
      "Error:16.442\n",
      "Error:16.660\n",
      "Error:16.325\n",
      "Error:16.041\n",
      "Error:16.699\n",
      "Error:15.950\n",
      "Error:16.410\n",
      "Error:16.091\n",
      "Error:16.316\n",
      "Error:15.419\n",
      "Error:15.724\n",
      "Error:15.798\n",
      "Error:16.016\n",
      "Error:16.054\n",
      "Error:15.876\n",
      "Error:15.606\n",
      "Error:16.131\n",
      "Error:16.002\n",
      "Error:16.082\n",
      "Error:15.262\n",
      "Error:15.715\n",
      "Error:14.957\n",
      "Error:14.887\n",
      "Error:15.621\n",
      "Error:15.383\n",
      "Error:14.756\n",
      "Error:15.494\n",
      "Error:15.201\n",
      "Error:15.062\n",
      "Error:15.061\n",
      "Error:15.488\n",
      "Error:15.378\n",
      "Error:15.089\n",
      "Error:14.783\n",
      "Error:14.848\n",
      "Error:14.372\n",
      "Error:14.755\n",
      "Error:15.298\n",
      "Error:14.837\n",
      "Error:15.139\n",
      "Error:14.768\n",
      "Error:14.447\n",
      "Error:14.551\n",
      "Error:14.558\n"
     ]
    }
   ],
   "source": [
    "err = 0.0\n",
    "l_rate = 0.01\n",
    "\n",
    "for i in range(len(X)): \n",
    "    err += fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999: \n",
    "        print (\"Error:{:.3f}\".format(err / 1000))\n",
    "        err = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can then create a function calculate the vector of outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f_y = theano.function([t_h0, t_inp], v_y, allow_input_downcast = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And then calculated the actual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred = np.argmax(f_y(np.zeros(n_hidden), X[6]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "act = np.argmax(X[6], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 'n', '?', ' ', 'I', 's']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indices_char[o] for o in act]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'e', ' ', ' ', ' ', 'T', 't', ' ']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indices_char[o] for o in pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Set up basic functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we're going to try to repeat the above theano RNN, using just pure python (and numpy). Which means, we have to do everything ourselves, including defining the basic functions of a neural net! Below are all of the definitions, along with tests to check that they give the same answers as theano. The functions ending in _d are the derivatives of each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x): return 1/(1+np.exp(-x))\n",
    "def sigmoid_d(x): \n",
    "    output = sigmoid(x)\n",
    "    return output*(1-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def relu(x): return np.maximum(0., x)\n",
    "def relu_d(x): return (x > 0.)*1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "relu(np.array([3.,-3.])), relu_d(np.array([3.,-3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "relu(np.array([3.,-3.])), relu_d(np.array([3.,-3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dist(a,b): return pow(a-b,2)\n",
    "def dist_d(a,b): return 2*(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eps = 1e-7\n",
    "def x_entropy(pred, actual): \n",
    "    return -np.sum(actual * np.log(np.clip(pred, eps, 1-eps)))\n",
    "def x_entropy_d(pred, actual): return -actual/pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def softmax(x): return np.exp(x)/np.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def softmax_d(x):\n",
    "    sm = softmax(x)\n",
    "    res = np.expand_dims(-sm,-1)*sm\n",
    "    res[np.diag_indices_from(res)] = sm*(1-sm)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_preds = np.array([0.2,0.7,0.1])\n",
    "test_actuals = np.array([0.,1.,0.])\n",
    "nnet.categorical_crossentropy(test_preds, test_actuals).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_entropy(test_preds, test_actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_inp = T.dvector()\n",
    "test_out = nnet.categorical_crossentropy(test_inp, test_actuals)\n",
    "test_grad = theano.function([test_inp], T.grad(test_out, test_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_grad(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_entropy_d(test_preds, test_actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pre_pred = random(oh_x_rnn[0][0].shape)\n",
    "preds = softmax(pre_pred)\n",
    "actual = oh_x_rnn[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.allclose(softmax_d(pre_pred).dot(loss_d(preds,actual)), preds-actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "softmax(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nnet.softmax(test_preds).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_out = T.flatten(nnet.softmax(test_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_grad = theano.function([test_inp], theano.gradient.jacobian(test_out, test_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_grad(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "softmax_d(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "act=relu\n",
    "act_d = relu_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss=x_entropy\n",
    "loss_d=x_entropy_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def scan(fn, start, seq):\n",
    "    res = []\n",
    "    prev = start\n",
    "    for s in seq:\n",
    "        app = fn(prev, s)\n",
    "        res.append(app)\n",
    "        prev = app\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scan(lambda prev,curr: prev+curr, 0, range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Set up training\n",
    "\n",
    "Let's now build the functions to do the forward and backward passes of our RNN. First, define our data and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inp = oh_x_rnn\n",
    "outp = oh_y_rnn\n",
    "n_input = vocab_size\n",
    "n_output = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inp.shape, outp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's the function to do a single forward pass of an RNN, for a single character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def one_char(prev, item):\n",
    "    # Previous state\n",
    "    tot_loss, pre_hidden, pre_pred, hidden, ypred = prev\n",
    "    # Current inputs and output\n",
    "    x, y = item\n",
    "    pre_hidden = np.dot(x,w_x) + np.dot(hidden,w_h)\n",
    "    hidden = act(pre_hidden)\n",
    "    pre_pred = np.dot(hidden,w_y)\n",
    "    ypred = softmax(pre_pred)\n",
    "    return (\n",
    "        # Keep track of loss so we can report it\n",
    "        tot_loss+loss(ypred, y),\n",
    "        # Used in backprop\n",
    "        pre_hidden, pre_pred, \n",
    "        # Used in next iteration\n",
    "        hidden, \n",
    "        # To provide predictions\n",
    "        ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We use scan to apply the above to a whole sequence of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_chars(n): return zip(inp[n], outp[n])\n",
    "def one_fwd(n): return scan(one_char, (0,0,0,np.zeros(n_hidden),0), get_chars(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can define the backward step. We use a loop to go through every element of the sequence. The derivatives are applying the chain rule to each step, and accumulating the gradients across the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# \"Columnify\" a vector\n",
    "def col(x): return x[:,newaxis]\n",
    "\n",
    "def one_bkwd(args, n):\n",
    "    global w_x,w_y,w_h\n",
    "\n",
    "    i=inp[n]  # 8x86\n",
    "    o=outp[n] # 8x86\n",
    "    d_pre_hidden = np.zeros(n_hidden) # 256\n",
    "    for p in reversed(range(len(i))):\n",
    "        totloss, pre_hidden, pre_pred, hidden, ypred = args[p]\n",
    "        x=i[p] # 86\n",
    "        y=o[p] # 86\n",
    "        d_pre_pred = softmax_d(pre_pred).dot(loss_d(ypred,y))  # 86\n",
    "        d_pre_hidden = (np.dot(d_pre_hidden, w_h.T) \n",
    "                        + np.dot(d_pre_pred,w_y.T)) * act_d(pre_hidden) # 256\n",
    "\n",
    "        # d(loss)/d(w_y) = d(loss)/d(pre_pred) * d(pre_pred)/d(w_y)\n",
    "        w_y -= col(hidden) * d_pre_pred * alpha\n",
    "        # d(loss)/d(w_h) = d(loss)/d(pre_hidden[p-1]) * d(pre_hidden[p-1])/d(w_h)\n",
    "        if (p>0): w_h -= args[p-1][3].dot(d_pre_hidden) * alpha\n",
    "        w_x -= col(x)*d_pre_hidden * alpha\n",
    "    return d_pre_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can set up our initial weight matrices. Note that we're not using bias at all in this example, in order to keep things simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scale=math.sqrt(2./n_input)\n",
    "w_x = normal(scale=scale, size=(n_input,n_hidden))\n",
    "w_y = normal(scale=scale, size=(n_hidden, n_output))\n",
    "w_h = np.eye(n_hidden, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our loop looks much like the theano loop in the previous section, except that we have to call the backwards step ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "overallError=0\n",
    "alpha=0.0001\n",
    "for n in range(10000):\n",
    "    res = one_fwd(n)\n",
    "    overallError+=res[-1][0]\n",
    "    deriv = one_bkwd(res, n)\n",
    "    if(n % 1000 == 999):\n",
    "        print (\"Error:{:.4f}; Gradient:{:.5f}\".format(\n",
    "                overallError/1000, np.linalg.norm(deriv)))\n",
    "        overallError=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Keras GRU\n",
    "\n",
    "Identical to the last keras rnn, but a GRU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        GRU(n_hidden, return_sequences=True, input_shape=(cs, vocab_size),\n",
    "                  activation='relu', inner_init='identity'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit(oh_x_rnn, oh_y_rnn, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_nexts_oh(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Theanu GRR\n",
    "\n",
    "### Separate weights\n",
    "\n",
    "The theano GRU looks just like the simple theano RNN, except for the use of the reset and update gates. Each of these gates requires its own hidden and input weights, so we add those to our weight matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "W_h = id_and_bias(n_hidden)\n",
    "W_x = init_wgts(n_input, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "rW_h = init_wgts(n_hidden, n_hidden)\n",
    "rW_x = wgts_and_bias(n_input, n_hidden)\n",
    "uW_h = init_wgts(n_hidden, n_hidden)\n",
    "uW_x = wgts_and_bias(n_input, n_hidden)\n",
    "w_all = list(chain.from_iterable([W_h, W_y, uW_x, rW_x]))\n",
    "w_all.extend([W_x, uW_h, rW_h])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's the definition of a gate - it's just a sigmoid applied to the addition of the dot products of the input vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gate(x, h, W_h, W_x, b_x):\n",
    "    return nnet.sigmoid(T.dot(x, W_x) + b_x + T.dot(h, W_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our step is nearly identical to before, except that we multiply our hidden state by our reset gate, and we update our hidden state based on the update gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W_h, b_h, W_y, b_y, uW_x, ub_x, rW_x, rb_x, W_x, uW_h, rW_h):\n",
    "    reset = gate(x, h, rW_h, rW_x, rb_x)\n",
    "    update = gate(x, h, uW_h, uW_x, ub_x)\n",
    "    h_new = gate(x, h * reset, W_h, W_x, b_h)\n",
    "    h = update*h + (1-update)*h_new\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Everything from here on is identical to our simple RNN in theano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp, \n",
    "                            outputs_info=[t_h0, None], non_sequences=w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "upd = upd_dict(w_all, g_all, lr)\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "err=0.0; l_rate=0.1\n",
    "for i in range(len(X)): \n",
    "    err+=fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999: \n",
    "        l_rate *= 0.95\n",
    "        print (\"Error:{:.2f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Combined weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can make the previous section simpler and faster by concatenating the hidden and input matrices and inputs together. We're not going to step through this cell by cell - you'll see it's identical to the previous section except for this concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "W = (shared(np.concatenate([np.eye(n_hidden), normal(size=(n_input, n_hidden))])\n",
    "            .astype(np.float32)), init_bias(n_hidden))\n",
    "\n",
    "rW = wgts_and_bias(n_input+n_hidden, n_hidden)\n",
    "uW = wgts_and_bias(n_input+n_hidden, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "w_all = list(chain.from_iterable([W, W_y, uW, rW]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gate(m, W, b): return nnet.sigmoid(T.dot(m, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W, b, W_y, b_y, uW, ub, rW, rb):\n",
    "    m = T.concatenate([h, x])\n",
    "    reset = gate(m, rW, rb)\n",
    "    update = gate(m, uW, ub)\n",
    "    m = T.concatenate([h*reset, x])\n",
    "    h_new = gate(m, W, b)\n",
    "    h = update*h + (1-update)*h_new\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp, \n",
    "                            outputs_info=[t_h0, None], non_sequences=w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def upd_dict(wgts, grads, lr): \n",
    "    return OrderedDict({w: w-g*lr for (w,g) in zip(wgts,grads)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "upd = upd_dict(w_all, g_all, lr)\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "err=0.0; l_rate=0.01\n",
    "for i in range(len(X)): \n",
    "    err+=fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999: \n",
    "        print (\"Error:{:.2f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
