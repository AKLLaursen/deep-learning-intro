{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to RNN\n",
    "\n",
    "We use Nietsche text data to showcase how Recurrant neural networks work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup libraries and functions.\n",
    "\n",
    "We start by importing various libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plots displayed inline in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Make Python 3 consistent\n",
    "from __future__ import print_function, division\n",
    "\n",
    "# Make help libraries available\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/ubuntu/personal-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "import math\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Input, BatchNormalization\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import get_file, to_categorical\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "import theano\n",
    "from theano import shared, tensor as T\n",
    "from theano.tensor.nnet import nnet\n",
    "\n",
    "from numpy.random import normal\n",
    "from itertools import chain\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setup data\n",
    "\n",
    "We're going to download the collected works of Nietzsche to use as our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt',\n",
    "                origin = \"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's consider an example. We see that the text is very convoluted (haha)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are thinkers who believe in the saints.\r\n",
      "\r\n",
      "\r\n",
      "144\r\n",
      "\r\n",
      "It stands to reason that this sketch of the saint, made upon the model\r\n",
      "of the whole species, can be confronted with many opposing sketches that\r\n",
      "would create a more agreeable impression. There are certain exceptions\r\n",
      "among the species who distinguish themselves either by especial\r\n",
      "gentleness or especial humanity, and perhaps by the strength of their\r\n",
      "own personality. Others are in the highest degree fascinating because\r\n",
      "certain of their delusions shed a particular glow over their whole\r\n",
      "being, as is the case with the founder of christianity who took himself\r\n",
      "for the only begotten son of God and hence felt himself sinless; so that\r\n",
      "through his imagination--that should not be too harshly judged since the\r\n",
      "whole of antiquity swarmed with sons of god--he attained the same goal,\r\n",
      "the sense of complete sinlessness, complete irresponsibility, that can\r\n",
      "now be attained by every individual through science.--In the same manner\r\n",
      "I have viewed the saints of India who occupy an intermediate station\r\n",
      "between the christian saints and the Greek philosophers and hence are\r\n",
      "not to be regarded as a pure type. Knowledge and science--as far as they\r\n",
      "existed--and superiority to the rest of mankind by logical discipline\r\n",
      "and training of the intellectual powers were insisted upon by the\r\n",
      "Buddhists as essential to sanctity, just as they were denounced by the\r\n",
      "christian world as the indications of sinfulness."
     ]
    }
   ],
   "source": [
    "!tail {path} -n25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We then make a list of all charcters used in the text. And determine the size of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 86\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sometimes it's useful to have a zero value in the dataset, e.g. for padding, so we add that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We then make a dict for characters and for indices. So each character gets mapped to an indecy and back again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "idx will be the data we use from now own - it simply converts all the characters to their index (based on the mapping above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Consider the first ten characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Corresponding to (Note the annoying line feeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3 character unrolled model\n",
    "\n",
    "We make a model to predict the fourth character based on the previous three caracters. We do this using the standard functional API in Keras. So we showcase how to build a RNN like model the hard way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Create inputs\n",
    "\n",
    "Create a list of every 4th character, starting at the 0th, 1st, 2nd, then 3rd characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cs = 3\n",
    "c1_dat = [idx[i] for i in xrange(0, len(idx) - 1 - cs, cs)]\n",
    "c2_dat = [idx[i + 1] for i in xrange(0, len(idx) - 1 - cs, cs)]\n",
    "c3_dat = [idx[i + 2] for i in xrange(0, len(idx) - 1 - cs, cs)]\n",
    "c4_dat = [idx[i + 3] for i in xrange(0, len(idx) - 1 - cs, cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We convert to numpy arrays by stacking, and thus get the inputs to out model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat[:-2])\n",
    "x2 = np.stack(c2_dat[:-2])\n",
    "x3 = np.stack(c3_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And the same to get our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c4_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So we can consider the first four inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40, 30, 29,  1]), array([42, 25,  1, 43]), array([29, 27,  1, 45]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 29,  1, 40])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note the shame. We have 1 dimensional arrays of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200297,), (200297,), (200297,), (200297,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, x2.shape, x3.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We then state the number of latent factors to create in the embedding (i.e. the size of the embedding matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create inputs and embedding outputs for each of our three character inputs. (Note each use the same, so we create it as a function returning the input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape = (1, ), dtype = 'int64', name = name)\n",
    "    emb = Embedding(n_in, n_out, input_length = 1)(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create input and output for each three character input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c1_in, c1 = embedding_input('c1', vocab_size, n_fac)\n",
    "c2_in, c2 = embedding_input('c2', vocab_size, n_fac)\n",
    "c3_in, c3 = embedding_input('c3', vocab_size, n_fac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Create and train unrolled model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pick a size for our hidden statem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is the layer operation from input to hidden (the 'green arrow' from our diagram). Note that it is not activated yet, we have yet to apply a layer into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation = 'relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our first hidden activation is simply this function applied to the result of the embedding of the first character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c1_hidden = dense_in(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is the layer operation from hidden to hidden, (the 'orange arrow' from our diagram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dense_hidden = Dense(n_hidden, activation = 'tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our second and third hidden activations sum up the previous hidden state (after applying dense_hidden) to the new input state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c2_dense = dense_in(c2)\n",
    "hidden_2 = dense_hidden(c1_hidden)\n",
    "c2_hidden = add([c2_dense, hidden_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c3_dense = dense_in(c3)\n",
    "hidden_3 = dense_hidden(c2_hidden)\n",
    "c3_hidden = add([c3_dense, hidden_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is the layer operation from hidden to output, (the 'blue arrow' from our diagram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dense_out = Dense(vocab_size, activation = 'softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The third hidden state is the input to our output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c4_out = dense_out(c3_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can now define our model using the three inputs (which we defined above), and the output from the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Model([c1_in, c2_in, c3_in], c4_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And finally we can fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200297/200297 [==============================] - 12s - loss: 2.4025    \n",
      "Epoch 2/10\n",
      "200297/200297 [==============================] - 12s - loss: 2.2607    \n",
      "Epoch 3/10\n",
      "200297/200297 [==============================] - 12s - loss: 2.2072    \n",
      "Epoch 4/10\n",
      "200297/200297 [==============================] - 12s - loss: 2.1623    \n",
      "Epoch 5/10\n",
      "200297/200297 [==============================] - 12s - loss: 2.1292    \n",
      "Epoch 6/10\n",
      "200297/200297 [==============================] - 12s - loss: 2.1087    \n",
      "Epoch 7/10\n",
      "200297/200297 [==============================] - 12s - loss: 2.0943    \n",
      "Epoch 8/10\n",
      "200297/200297 [==============================] - 12s - loss: 2.0847    \n",
      "Epoch 9/10\n",
      "200297/200297 [==============================] - 12s - loss: 2.0768    \n",
      "Epoch 10/10\n",
      "200297/200297 [==============================] - 12s - loss: 2.0698    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f96614f5090>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size = 64, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We define a function that returns the predictions for a given input sequence of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict(arrs)\n",
    "    i = np.argmax(p)\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We then try different inputs in order to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('phi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' an')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Seems to work great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## First RNN using low level parts of Keras API\n",
    "\n",
    "We create a sample unrolled RNN the hard way using the functional API of Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Create input\n",
    "\n",
    "This is the size of our unrolled RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For each of 0 through 7, create a list of every 8th character with that starting point. These will be the 8 inputs to out model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i + n] for i in xrange(0, len(idx) - 1 - cs, cs)] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Then create a list of the next character in each of these series. This will be the labels for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [idx[i + cs] for i in xrange(0, len(idx) - 1 - cs, cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can then create the input as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xs = [np.stack(c[:-2]) for c in c_in_dat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So we have an array of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, (75110,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs), xs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And for the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Which is a simple one dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75110,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So each column below is one series of 8 characters from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([40,  1, 33,  2, 72, 67, 73,  2]),\n",
       " array([42,  1, 38, 44,  2,  9, 61, 73]),\n",
       " array([29, 43, 31, 71, 54,  9, 58, 61]),\n",
       " array([30, 45,  2, 74,  2, 76, 67, 58]),\n",
       " array([25, 40, 73, 73, 76, 61, 24, 71]),\n",
       " array([27, 40, 61, 61, 68, 54,  2, 58]),\n",
       " array([29, 39, 54,  2, 66, 73, 33,  2]),\n",
       " array([ 1, 43, 73, 62, 54,  2, 72, 67])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[xs[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "...and this is the next character after each sequence. Which as we can see is also the first character of each sequence after the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 33,  2, 72, 67, 73,  2, 68])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We then state the number of latent factors to create in the embedding (i.e. the size of the embedding matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We start by defining the embedding input layers again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1, ), dtype = 'int64', name = name + '_in')\n",
    "    emb = Embedding(n_in, n_out, input_length = 1, name = name + '_emb')(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We then create the embeddings for each eight characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c_ins = [embedding_input('c' + str(n), vocab_size, n_fac) for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can then define our dense layers. That is the input, hidden and output dense layers. Note again that these are not activated before we pass something to them.\n",
    "Also note that we initialise the weights using the identity matrix rather than eg. Xavier initialisation. That way we start out by having the hidden state stay the same for each layer of the RNN. That makes intuitive sense, as absent of any new information, we would imagine each layer to be the same. It also makes sense from an empirical point of view, as demonstrated by [this paper](https://arxiv.org/pdf/1504.00941.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "\n",
    "dense_in = Dense(n_hidden, activation = 'relu')\n",
    "dense_hidden = Dense(n_hidden, activation = 'relu', kernel_initializer = 'identity')\n",
    "dense_out = Dense(vocab_size, activation = 'softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first character of each sequence goes through dense_in(), to create our first hidden activations. Note that each element in the list c_ins is a tuple with the input layer and the output flattened embedding layer. We pass the output to the next layer, in accordance to the functional API of Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hidden = dense_in(c_ins[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Then for each successive layer we combine the output of dense_in() on the next character with the output of dense_hidden() on the current hidden state, to create the new hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = add([c_dense, hidden])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Putting the final hidden state through dense_out() gives us our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c_out = dense_out(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So now we can create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Model([c[0] for c in c_ins], c_out)\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And then fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75110/75110 [==============================] - 10s - loss: 2.5354    \n",
      "Epoch 2/12\n",
      "75110/75110 [==============================] - 10s - loss: 2.2505    \n",
      "Epoch 3/12\n",
      "75110/75110 [==============================] - 10s - loss: 2.1474    \n",
      "Epoch 4/12\n",
      "75110/75110 [==============================] - 10s - loss: 2.0765    \n",
      "Epoch 5/12\n",
      "75110/75110 [==============================] - 10s - loss: 2.0221    \n",
      "Epoch 6/12\n",
      "75110/75110 [==============================] - 10s - loss: 1.9759    \n",
      "Epoch 7/12\n",
      "75110/75110 [==============================] - 10s - loss: 1.9352    \n",
      "Epoch 8/12\n",
      "75110/75110 [==============================] - 10s - loss: 1.8997    \n",
      "Epoch 9/12\n",
      "75110/75110 [==============================] - 10s - loss: 1.8678    \n",
      "Epoch 10/12\n",
      "75110/75110 [==============================] - 10s - loss: 1.8398    \n",
      "Epoch 11/12\n",
      "75110/75110 [==============================] - 10s - loss: 1.8144    \n",
      "Epoch 12/12\n",
      "75110/75110 [==============================] - 10s - loss: 1.7923    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f965ee07fd0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, y, batch_size = 64, epochs = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Again we define a function to predict the next chracter of a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [np.array(char_indices[c])[np.newaxis] for c in inp]\n",
    "    p = model.predict(idxs)\n",
    "    return chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And we use some examples to test the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('this is ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Seems to work great again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## First RNN with high level parts of Keras API\n",
    "\n",
    "We recreate the recurrent neural network using the higher level api of Keras, instead of doing it manually with the functional api."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We define the number of hidden layers, factors, character steps and vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_hidden, n_fac, cs, vocab_size = (256, 42, 8, 86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Then define the model using the sequential API and the SimpleRNN class.\n",
    "\n",
    "Again, note that we initialise the weights using the identity matrix rather than eg. Xavier initialisation. That way we start out by having the hidden state stay the same for each layer of the RNN. That makes intuitive sense, as absent of any new information, we would imagine each layer to be the same. It also makes sense from an empirical point of view, as demonstrated by this paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length = cs),\n",
    "    SimpleRNN(n_hidden, activation = 'relu', recurrent_initializer = 'identity'),\n",
    "    Dense(vocab_size, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 8, 42)             3612      \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 256)               76544     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 86)                22102     \n",
      "=================================================================\n",
      "Total params: 102,258\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can then compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75110/75110 [==============================] - 12s - loss: 2.7546    \n",
      "Epoch 2/12\n",
      "75110/75110 [==============================] - 12s - loss: 2.2575    \n",
      "Epoch 3/12\n",
      "75110/75110 [==============================] - 12s - loss: 2.0555    \n",
      "Epoch 4/12\n",
      "75110/75110 [==============================] - 12s - loss: 1.9184    \n",
      "Epoch 5/12\n",
      "75110/75110 [==============================] - 12s - loss: 1.8155    \n",
      "Epoch 6/12\n",
      "75110/75110 [==============================] - 12s - loss: 1.7310    \n",
      "Epoch 7/12\n",
      "75110/75110 [==============================] - 12s - loss: 1.6643    \n",
      "Epoch 8/12\n",
      "75110/75110 [==============================] - 12s - loss: 1.6074    \n",
      "Epoch 9/12\n",
      "75110/75110 [==============================] - 12s - loss: 1.5622    \n",
      "Epoch 10/12\n",
      "75110/75110 [==============================] - 12s - loss: 1.5198    \n",
      "Epoch 11/12\n",
      "75110/75110 [==============================] - 12s - loss: 1.4858    \n",
      "Epoch 12/12\n",
      "75110/75110 [==============================] - 12s - loss: 1.4532    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f965a68be50>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.concatenate(xs, axis = 1), y, batch_size = 64, epochs = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can then test the model. Again, define a function returning the predicted character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_next_keras(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = np.array(idxs)[np.newaxis,:]\n",
    "    p = model.predict(arrs)[0]\n",
    "    return chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('this is ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Works great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Returning sequences using low level part of Keras API\n",
    "\n",
    "We now predict each character to a given sequence length using the previous characters. We move the output generation inside the loop and make it part of the RNN. So everytime we loop through the RNN, we predict the next character. I.e. we predict char 2 using char 1 and predict char 3 using char 1 and two and predict char 4 using char 1, char 2 and char 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To use a sequence model, we can leave our input unchanged - but we have to change our output to a sequence (of course!)\n",
    "Here, c_out_dat is identical to c_in_dat, but moved across 1 character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Previous\n",
    "#c_in_dat = [[idx[i + n] for i in xrange(0, len(idx) - 1 - cs, cs)]\n",
    "#            for n in range(cs)]\n",
    "# Now\n",
    "c_out_dat = [[idx[i + n] for i in xrange(1, len(idx) - cs, cs)]\n",
    "             for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So we now also have a sequence of outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ys = [np.stack(c[:-2]) for c in c_out_dat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Reading down each column shows one set of inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[40],\n",
       "        [ 1],\n",
       "        [33],\n",
       "        [ 2],\n",
       "        [72],\n",
       "        [67],\n",
       "        [73],\n",
       "        [ 2]]), array([[42],\n",
       "        [ 1],\n",
       "        [38],\n",
       "        [44],\n",
       "        [ 2],\n",
       "        [ 9],\n",
       "        [61],\n",
       "        [73]]), array([[29],\n",
       "        [43],\n",
       "        [31],\n",
       "        [71],\n",
       "        [54],\n",
       "        [ 9],\n",
       "        [58],\n",
       "        [61]]), array([[30],\n",
       "        [45],\n",
       "        [ 2],\n",
       "        [74],\n",
       "        [ 2],\n",
       "        [76],\n",
       "        [67],\n",
       "        [58]]), array([[25],\n",
       "        [40],\n",
       "        [73],\n",
       "        [73],\n",
       "        [76],\n",
       "        [61],\n",
       "        [24],\n",
       "        [71]]), array([[27],\n",
       "        [40],\n",
       "        [61],\n",
       "        [61],\n",
       "        [68],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [58]]), array([[29],\n",
       "        [39],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [66],\n",
       "        [73],\n",
       "        [33],\n",
       "        [ 2]]), array([[ 1],\n",
       "        [43],\n",
       "        [73],\n",
       "        [62],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [72],\n",
       "        [67]])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[xs[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([42,  1, 38, 44,  2,  9, 61, 73]),\n",
       " array([29, 43, 31, 71, 54,  9, 58, 61]),\n",
       " array([30, 45,  2, 74,  2, 76, 67, 58]),\n",
       " array([25, 40, 73, 73, 76, 61, 24, 71]),\n",
       " array([27, 40, 61, 61, 68, 54,  2, 58]),\n",
       " array([29, 39, 54,  2, 66, 73, 33,  2]),\n",
       " array([ 1, 43, 73, 62, 54,  2, 72, 67]),\n",
       " array([ 1, 33,  2, 72, 67, 73,  2, 68])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ys[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We define the input, hidden and output layers again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation = 'relu')\n",
    "dense_hidden = Dense(n_hidden, activation = 'relu', kernel_initializer = 'identity')\n",
    "dense_out = Dense(vocab_size, activation = 'softmax', name = 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're going to pass a vector of all zeros as our starting point - below's our input layers for that: So we have moved the first character inside the loop and now just initialise the hidden lyaer with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inp1 = Input(shape = (n_fac,), name = 'zeros')\n",
    "hidden = dense_in(inp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can then define the 8 layers. Note that we create a list of each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outs = []\n",
    "\n",
    "for i in range(cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = add([c_dense, hidden])\n",
    "    # every layer now has an output\n",
    "    outs.append(dense_out(hidden))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can then define and compile the model. Compared to the previous model, where we just predicted the final character of a sequence, out model specification now has two changes. 1) The out put is a list of 8 outputs, and 2) We add the first zero layer to our list of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Model([inp1] + [c[0] for c in c_ins], outs)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We need to pad out input layers, so we do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75110, 42)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = np.tile(np.zeros(n_fac), (len(xs[0]), 1))\n",
    "zeros.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75110/75110 [==============================] - 23s - loss: 20.1548 - output_loss_1: 2.7066 - output_loss_2: 2.5653 - output_loss_3: 2.5157 - output_loss_4: 2.4881 - output_loss_5: 2.4855 - output_loss_6: 2.4684 - output_loss_7: 2.4729 - output_loss_8: 2.4522    \n",
      "Epoch 2/12\n",
      "75110/75110 [==============================] - 23s - loss: 17.9093 - output_loss_1: 2.5139 - output_loss_2: 2.3524 - output_loss_3: 2.2395 - output_loss_4: 2.1807 - output_loss_5: 2.1685 - output_loss_6: 2.1507 - output_loss_7: 2.1665 - output_loss_8: 2.1371    \n",
      "Epoch 3/12\n",
      "75110/75110 [==============================] - 23s - loss: 17.2997 - output_loss_1: 2.4971 - output_loss_2: 2.3299 - output_loss_3: 2.1799 - output_loss_4: 2.0906 - output_loss_5: 2.0668 - output_loss_6: 2.0443 - output_loss_7: 2.0590 - output_loss_8: 2.0320    \n",
      "Epoch 4/12\n",
      "75110/75110 [==============================] - 23s - loss: 16.9270 - output_loss_1: 2.4899 - output_loss_2: 2.3197 - output_loss_3: 2.1482 - output_loss_4: 2.0380 - output_loss_5: 2.0017 - output_loss_6: 1.9750 - output_loss_7: 1.9891 - output_loss_8: 1.9654    \n",
      "Epoch 5/12\n",
      "75110/75110 [==============================] - 23s - loss: 16.6715 - output_loss_1: 2.4863 - output_loss_2: 2.3152 - output_loss_3: 2.1300 - output_loss_4: 2.0019 - output_loss_5: 1.9591 - output_loss_6: 1.9243 - output_loss_7: 1.9390 - output_loss_8: 1.9158    \n",
      "Epoch 6/12\n",
      "75110/75110 [==============================] - 23s - loss: 16.4831 - output_loss_1: 2.4841 - output_loss_2: 2.3131 - output_loss_3: 2.1169 - output_loss_4: 1.9768 - output_loss_5: 1.9255 - output_loss_6: 1.8870 - output_loss_7: 1.9009 - output_loss_8: 1.8788    \n",
      "Epoch 7/12\n",
      "75110/75110 [==============================] - 23s - loss: 16.3407 - output_loss_1: 2.4826 - output_loss_2: 2.3107 - output_loss_3: 2.1071 - output_loss_4: 1.9593 - output_loss_5: 1.9006 - output_loss_6: 1.8612 - output_loss_7: 1.8705 - output_loss_8: 1.8485    \n",
      "Epoch 8/12\n",
      "75110/75110 [==============================] - 23s - loss: 16.2260 - output_loss_1: 2.4811 - output_loss_2: 2.3095 - output_loss_3: 2.1000 - output_loss_4: 1.9443 - output_loss_5: 1.8807 - output_loss_6: 1.8367 - output_loss_7: 1.8481 - output_loss_8: 1.8258    \n",
      "Epoch 9/12\n",
      "75110/75110 [==============================] - 23s - loss: 16.1329 - output_loss_1: 2.4802 - output_loss_2: 2.3068 - output_loss_3: 2.0937 - output_loss_4: 1.9325 - output_loss_5: 1.8654 - output_loss_6: 1.8185 - output_loss_7: 1.8278 - output_loss_8: 1.8079    \n",
      "Epoch 10/12\n",
      "75110/75110 [==============================] - 23s - loss: 16.0514 - output_loss_1: 2.4788 - output_loss_2: 2.3055 - output_loss_3: 2.0897 - output_loss_4: 1.9230 - output_loss_5: 1.8513 - output_loss_6: 1.8030 - output_loss_7: 1.8094 - output_loss_8: 1.7907    \n",
      "Epoch 11/12\n",
      "75110/75110 [==============================] - 23s - loss: 15.9831 - output_loss_1: 2.4778 - output_loss_2: 2.3045 - output_loss_3: 2.0846 - output_loss_4: 1.9152 - output_loss_5: 1.8398 - output_loss_6: 1.7878 - output_loss_7: 1.7976 - output_loss_8: 1.7758    \n",
      "Epoch 12/12\n",
      "75110/75110 [==============================] - 22s - loss: 15.9232 - output_loss_1: 2.4770 - output_loss_2: 2.3032 - output_loss_3: 2.0813 - output_loss_4: 1.9085 - output_loss_5: 1.8298 - output_loss_6: 1.7784 - output_loss_7: 1.7819 - output_loss_8: 1.7631    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9651622d90>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([zeros] + xs, ys, batch_size = 64, epochs = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Again define a model returning predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_nexts(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict([np.zeros(n_fac)[np.newaxis,:]] + arrs)\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And run the model on our examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 't', ' ', 'i', 'n', ' ']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 'a', 'r', 't', ' ', 'o', 'f', ' ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e', 'n', 'e', 'i', 'o', 'f', ' ', 't']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q', 'u', 'e', 'e', 'n', 's', ' ', 'a']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['u', 'e', 's', 't', 'd', ' ', 'o', 'n']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Actually, going forward one character at a time, it seems to work pretty good all things considered!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Return sequences using high level part of Keras API\n",
    "\n",
    "We then create a return sequence model using the highest level Keras API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We reuse the number of hidden layers, factors, character steps and vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 42, 8, 86)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden, n_fac, cs, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To convert our previous keras model into a sequence model, simply add the 'return_sequences = True' parameter, and add TimeDistributed() around our dense layer. This is due to our output having 8x256 dimensions instead of 1x256 in a usual dense layer. This is due to us generating 8 outputs. So TimeDistributed() ensures that we get a dense layer for each of the 8 outputs, which will share the same weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length = cs),\n",
    "    SimpleRNN(n_hidden, return_sequences = True, activation = 'relu',\n",
    "              recurrent_initializer = 'identity'),\n",
    "    TimeDistributed(Dense(vocab_size, activation = 'softmax')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 8, 42)             3612      \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 8, 256)            76544     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 8, 86)             22102     \n",
      "=================================================================\n",
      "Total params: 102,258\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We then compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We then create the model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75110,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = [np.stack(c[:-2]) for c in c_in_dat]\n",
    "xs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Redefine ys, as we added a dimension earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75110,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = [np.stack(c[:-2]) for c in c_out_dat]\n",
    "ys[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_rnn = np.stack(xs, axis = 1)\n",
    "y_rnn = np.expand_dims(np.stack(ys, axis = 1), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Yielding the expected shape of ((75110, 8), (75110, 8, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75110, 8), (75110, 8, 1))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rnn.shape, y_rnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can then train the model and see that we obtain similar loss as earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75110/75110 [==============================] - 15s - loss: 2.4279    \n",
      "Epoch 2/8\n",
      "75110/75110 [==============================] - 15s - loss: 2.0019    \n",
      "Epoch 3/8\n",
      "75110/75110 [==============================] - 15s - loss: 1.8848    \n",
      "Epoch 4/8\n",
      "75110/75110 [==============================] - 15s - loss: 1.8230    \n",
      "Epoch 5/8\n",
      "75110/75110 [==============================] - 15s - loss: 1.7847    \n",
      "Epoch 6/8\n",
      "75110/75110 [==============================] - 15s - loss: 1.7582    \n",
      "Epoch 7/8\n",
      "75110/75110 [==============================] - 15s - loss: 1.7380    \n",
      "Epoch 8/8\n",
      "75110/75110 [==============================] - 15s - loss: 1.7225    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f964bf52710>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn, y_rnn, batch_size = 64, epochs = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And we can then test by defining the test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_keras(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arr = np.array(idxs)[np.newaxis,:]\n",
    "    p = model.predict(arr)[0]\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 's', ' ', 's', 's', ' ']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_keras(' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 'a', 'r', 't', ' ', 'o', 'f', ' ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['o', 'r', 't', 'i', 'o', 'f', ' ', 't']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_keras('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q', 'u', 'e', 'e', 'n', 's', ' ', 'a']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['u', 'i', 's', 's', 't', ' ', 'o', 'n']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_keras('queens a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Again a pretty good result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Stateful model in Keras\n",
    "\n",
    "How do we add state to a RNN? How to generate a model, that can handle long term dependencies?\n",
    "\n",
    "We alter the previous model by 1) not shuffling the input data and 2) stopping passing in zeroes for each itteration. That is we want to keep the hidden state for each itteration of 8 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bs = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A stateful model is easy to create (just add \"stateful=True\") but harder to train. We had to add batchnorm and use LSTM to get reasonable results. It is because we get activate using the weight matrix for each loop of the RNN. This yields hundred of  thousands weights in the state matrix. The training was solved in the LSTM model, where we use a neural net inside the loop, that decides how much of the state matrix to keep and how much to use at each activation.\n",
    "\n",
    "When using stateful in keras, you have to also add 'batch_input_shape' to the first layer, and fix the batch size there.\n",
    "\n",
    "This model, when shuffling is set to false, allows a build up of arbitrarily long dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length = cs, batch_input_shape = (bs, 8)),\n",
    "    BatchNormalization(),\n",
    "    LSTM(n_hidden, return_sequences = True, stateful = True),\n",
    "    TimeDistributed(Dense(vocab_size, activation = 'softmax')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We then compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since we're using a fixed batch shape, we have to ensure our inputs and outputs are a even multiple of the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mx = len(x_rnn) // bs * bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We then fit the model, remembering that Shuffle has to be set as False, as the ordering of the data now has to be ensured in order to estimate the long term dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "75072/75072 [==============================] - 49s - loss: 2.2510    \n",
      "Epoch 2/4\n",
      "75072/75072 [==============================] - 49s - loss: 1.9769    \n",
      "Epoch 3/4\n",
      "75072/75072 [==============================] - 48s - loss: 1.8967    \n",
      "Epoch 4/4\n",
      "75072/75072 [==============================] - 49s - loss: 1.8497    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f964573dbd0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size = bs, epochs = 4, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We lower the learning rate and run for some more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75072/75072 [==============================] - 50s - loss: 1.8056    \n",
      "Epoch 2/8\n",
      "75072/75072 [==============================] - 50s - loss: 1.7832    \n",
      "Epoch 3/8\n",
      "75072/75072 [==============================] - 50s - loss: 1.7621    \n",
      "Epoch 4/8\n",
      "75072/75072 [==============================] - 50s - loss: 1.7436    \n",
      "Epoch 5/8\n",
      "75072/75072 [==============================] - 50s - loss: 1.7268    \n",
      "Epoch 6/8\n",
      "75072/75072 [==============================] - 50s - loss: 1.7115    \n",
      "Epoch 7/8\n",
      "75072/75072 [==============================] - 50s - loss: 1.6975    \n",
      "Epoch 8/8\n",
      "75072/75072 [==============================] - 50s - loss: 1.6844    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f96451d1cd0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "\n",
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size = bs, epochs = 8, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So using the state keeping model makes us able to lower the loss quite a bit, compared to the model not keeping the state.\n",
    "\n",
    "We can do even better by adding a second RNN which uses the first RNN as input. See this in rnn-example.ipynb notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## One-hot sequence model with keras\n",
    "\n",
    "We have previously not one hot encoded out output. This is due tio the fact that Keras impelements the sparse categorical crossentropy loss function, which is identical to categorical crossentropy, but takes an integer target instead of a binary one hot encoded target. This is usefull, when you have very large vocabularies with hundreds of thousands words.\n",
    "\n",
    "However, in order to make thins simpler, we will use one hot encoding, when creating our hand craftet Theano model. This is the keras version of the theano model that we're about to create.\n",
    "\n",
    "So below we use normal cross enthropy and use no embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        SimpleRNN(n_hidden, return_sequences = True, input_shape = (cs, vocab_size),\n",
    "                  activation = 'relu', recurrent_initializer = 'identity'),\n",
    "        TimeDistributed(Dense(vocab_size, activation = 'softmax')),\n",
    "    ])\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we do not use an embedding layer and we use normal categorical crossenthropy, we have to one hot encode out input and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75110, 8, 86), (75110, 8, 86))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_ys = [to_categorical(o, vocab_size) for o in ys]\n",
    "oh_y_rnn=np.stack(oh_ys, axis=1)\n",
    "\n",
    "oh_xs = [to_categorical(o, vocab_size) for o in xs]\n",
    "oh_x_rnn=np.stack(oh_xs, axis=1)\n",
    "\n",
    "oh_x_rnn.shape, oh_y_rnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can then fit this model, an see that it performs on the same level as the model using embeddings and sparse categorical crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75110/75110 [==============================] - 11s - loss: 2.4478    \n",
      "Epoch 2/8\n",
      "75110/75110 [==============================] - 11s - loss: 2.0380    \n",
      "Epoch 3/8\n",
      "75110/75110 [==============================] - 11s - loss: 1.9240    \n",
      "Epoch 4/8\n",
      "75110/75110 [==============================] - 11s - loss: 1.8594    \n",
      "Epoch 5/8\n",
      "75110/75110 [==============================] - 11s - loss: 1.8168    \n",
      "Epoch 6/8\n",
      "75110/75110 [==============================] - 11s - loss: 1.7862    \n",
      "Epoch 7/8\n",
      "75110/75110 [==============================] - 11s - loss: 1.7624    \n",
      "Epoch 8/8\n",
      "75110/75110 [==============================] - 11s - loss: 1.7436    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9646093ad0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(oh_x_rnn, oh_y_rnn, batch_size = 64, epochs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_oh(inp):\n",
    "    idxs = np.array([char_indices[c] for c in inp])\n",
    "    arr = to_categorical(idxs, vocab_size)\n",
    "    p = model.predict(arr[np.newaxis,:])[0]\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 's', ' ', 'c', 's', ' ']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_oh(' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 'a', 'r', 't', ' ', 'o', 'f', ' ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e', 'r', 't', ' ', 'o', 'f', ' ', 't']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_oh('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q', 'u', 'e', 'e', 'n', 's', ' ', 'a']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['u', 'e', 'n', 's', 'c', ' ', 'o', 'n']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_oh('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano RNN\n",
    "\n",
    "In this section we build an RNN in pure Theano, using one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = vocab_size\n",
    "n_output = vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using raw theano, we have to create our weight matrices and bias vectors ourselves - here are the functions we'll use to do so (using glorot initialization).\n",
    "The return values are wrapped in shared(), which is how we tell theano that it can manage this data (copying it to and from the GPU as necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_wgts(rows, cols):\n",
    "    # Initialise weights with random numbers of given scale.\n",
    "    \n",
    "    # Calculate the scale of the random numbers\n",
    "    scale = math.sqrt(2 / rows)\n",
    "    \n",
    "    # Create the random numbers from normal distribution. We use shared as wrapper\n",
    "    # to pass it to Theano for later use in the GPU calculations.\n",
    "    return shared(normal(scale = scale, size = (rows, cols)).astype(np.float32))\n",
    "\n",
    "def init_bias(rows):\n",
    "    # Intialise bias by using a simple 0 vector. We use shared as wrapper\n",
    "    # to pass it to Theano for later use in the GPU calculations.\n",
    "    \n",
    "    return shared(np.zeros(rows, dtype = np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We return the weights and biases together as a tuple. For the hidden weights, we'll use an identity initialization (as recommended by [Hinton](https://arxiv.org/abs/1504.00941).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wgts_and_bias(n_in, n_out):\n",
    "    # Generate weights and bias for input and output layers\n",
    "    \n",
    "    # n_in rows and n_out columns\n",
    "    return init_wgts(n_in, n_out), init_bias(n_out)\n",
    "\n",
    "def id_and_bias(n):\n",
    "    # Generate weights and bias for hidden layers layers\n",
    "    \n",
    "    # Use identity matrix as initialisation as proposed by Hinton.\n",
    "    return shared(np.eye(n, dtype = np.float32)), init_bias(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano doesn't actually do any computations until we explicitly compile and evaluate the function (at which point it'll be turned into CUDA code and sent off to the GPU). So our job is to describe the computations that we'll want theano to do - the first step is to tell theano what inputs we'll be providing to our computation. So we construct some input and output tensors in the form of matrixes, vectors and scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify variables.\n",
    "t_inp = T.matrix('inp')\n",
    "t_outp = T.matrix('outp')\n",
    "t_h0 = T.vector('h0')\n",
    "lr = T.scalar('lr')\n",
    "\n",
    "all_args = [t_h0, t_inp, t_outp, lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to create our intial weight matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Weights and bias to hidden layer\n",
    "W_h = id_and_bias(n_hidden)\n",
    "\n",
    "# Weights and bias to input\n",
    "W_x = wgts_and_bias(n_input, n_hidden)\n",
    "\n",
    "# Weights and bias to output\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "\n",
    "# Gather in a single list\n",
    "w_all = list(chain.from_iterable([W_h, W_x, W_y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano handles looping (in this case looping trough our RNN) by using the [GPU scan](http://http.developer.nvidia.com/GPUGems3/gpugems3_ch39.html) operation. We have to tell theano what to do at each step through the scan - this is the function we'll use, which does a single forward pass for one character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W_h, b_h, W_x, b_x, W_y, b_y):\n",
    "    \n",
    "    # Calculate the hidden activations\n",
    "    h = nnet.relu(T.dot(x, W_x) + b_x + T.dot(h, W_h) + b_h)\n",
    "    \n",
    "    # Calculate the output activations\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    \n",
    "    # Return both (the 'Flatten()' is to work around a theano bug)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can provide everything necessary for the scan operation, so we can setup that up - we have to pass in the function to call at each step, the sequence to step through, the initial values of the outputs, and any other arguments to pass to the step function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform one function for every sequence\n",
    "[v_h, v_y], _ = theano.scan(step,\n",
    "                            sequences = t_inp, \n",
    "                            outputs_info = [t_h0, None],\n",
    "                            non_sequences = w_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate our loss function, and all of our gradients, with just a couple of lines of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We even have to show theano how to do SGD - so we set up this dictionary of updates to complete after every forward pass, which apply to standard SGD update rule to every weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upd_dict(wgts, grads, lr): \n",
    "    return OrderedDict({w: w - g * lr for (w, g) in zip(wgts, grads)})\n",
    "\n",
    "upd = upd_dict(w_all, g_all, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're finally ready to compile the function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = theano.function(all_args, error, updates = upd, allow_input_downcast = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then specify the actual values for the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75110, 8, 86), (75110, 8, 86))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = oh_x_rnn\n",
    "Y = oh_y_rnn\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use it, we simply loop through our input data, calling the function compiled above, and printing our progress from time to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:25.154\n",
      "Error:21.470\n",
      "Error:20.950\n",
      "Error:19.943\n",
      "Error:18.830\n",
      "Error:19.258\n",
      "Error:19.059\n",
      "Error:18.418\n",
      "Error:17.941\n",
      "Error:18.256\n",
      "Error:17.512\n",
      "Error:17.630\n",
      "Error:18.476\n",
      "Error:17.351\n",
      "Error:16.812\n",
      "Error:17.733\n",
      "Error:17.370\n",
      "Error:17.227\n",
      "Error:16.858\n",
      "Error:16.707\n",
      "Error:16.542\n",
      "Error:16.401\n",
      "Error:16.709\n",
      "Error:16.189\n",
      "Error:16.872\n",
      "Error:16.627\n",
      "Error:16.081\n",
      "Error:16.308\n",
      "Error:16.277\n",
      "Error:16.445\n",
      "Error:16.746\n",
      "Error:16.442\n",
      "Error:16.660\n",
      "Error:16.325\n",
      "Error:16.041\n",
      "Error:16.699\n",
      "Error:15.950\n",
      "Error:16.410\n",
      "Error:16.091\n",
      "Error:16.316\n",
      "Error:15.419\n",
      "Error:15.724\n",
      "Error:15.798\n",
      "Error:16.016\n",
      "Error:16.054\n",
      "Error:15.876\n",
      "Error:15.606\n",
      "Error:16.131\n",
      "Error:16.002\n",
      "Error:16.082\n",
      "Error:15.262\n",
      "Error:15.715\n",
      "Error:14.957\n",
      "Error:14.887\n",
      "Error:15.621\n",
      "Error:15.383\n",
      "Error:14.756\n",
      "Error:15.494\n",
      "Error:15.201\n",
      "Error:15.062\n",
      "Error:15.061\n",
      "Error:15.488\n",
      "Error:15.378\n",
      "Error:15.089\n",
      "Error:14.783\n",
      "Error:14.848\n",
      "Error:14.372\n",
      "Error:14.755\n",
      "Error:15.298\n",
      "Error:14.837\n",
      "Error:15.139\n",
      "Error:14.768\n",
      "Error:14.447\n",
      "Error:14.551\n",
      "Error:14.558\n"
     ]
    }
   ],
   "source": [
    "err = 0.0\n",
    "l_rate = 0.01\n",
    "\n",
    "for i in range(len(X)): \n",
    "    err += fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999: \n",
    "        print (\"Error:{:.3f}\".format(err / 1000))\n",
    "        err = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a function calculate the vector of outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_y = theano.function([t_h0, t_inp], v_y, allow_input_downcast = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then calculated the actual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.argmax(f_y(np.zeros(n_hidden), X[6]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act = np.argmax(X[6], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 'n', '?', ' ', 'I', 's']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indices_char[o] for o in act]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'e', ' ', ' ', ' ', 'T', 't', ' ']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indices_char[o] for o in pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Set up basic functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we're going to try to repeat the above theano RNN, using just pure python (and numpy). Which means, we have to do everything ourselves, including defining the basic functions of a neural net! Below are all of the definitions, along with tests to check that they give the same answers as theano. The functions ending in _d are the derivatives of each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x): return 1/(1+np.exp(-x))\n",
    "def sigmoid_d(x): \n",
    "    output = sigmoid(x)\n",
    "    return output*(1-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def relu(x): return np.maximum(0., x)\n",
    "def relu_d(x): return (x > 0.)*1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "relu(np.array([3.,-3.])), relu_d(np.array([3.,-3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "relu(np.array([3.,-3.])), relu_d(np.array([3.,-3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dist(a,b): return pow(a-b,2)\n",
    "def dist_d(a,b): return 2*(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eps = 1e-7\n",
    "def x_entropy(pred, actual): \n",
    "    return -np.sum(actual * np.log(np.clip(pred, eps, 1-eps)))\n",
    "def x_entropy_d(pred, actual): return -actual/pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def softmax(x): return np.exp(x)/np.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def softmax_d(x):\n",
    "    sm = softmax(x)\n",
    "    res = np.expand_dims(-sm,-1)*sm\n",
    "    res[np.diag_indices_from(res)] = sm*(1-sm)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_preds = np.array([0.2,0.7,0.1])\n",
    "test_actuals = np.array([0.,1.,0.])\n",
    "nnet.categorical_crossentropy(test_preds, test_actuals).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_entropy(test_preds, test_actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_inp = T.dvector()\n",
    "test_out = nnet.categorical_crossentropy(test_inp, test_actuals)\n",
    "test_grad = theano.function([test_inp], T.grad(test_out, test_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_grad(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_entropy_d(test_preds, test_actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pre_pred = random(oh_x_rnn[0][0].shape)\n",
    "preds = softmax(pre_pred)\n",
    "actual = oh_x_rnn[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.allclose(softmax_d(pre_pred).dot(loss_d(preds,actual)), preds-actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "softmax(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nnet.softmax(test_preds).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_out = T.flatten(nnet.softmax(test_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_grad = theano.function([test_inp], theano.gradient.jacobian(test_out, test_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_grad(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "softmax_d(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "act=relu\n",
    "act_d = relu_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss=x_entropy\n",
    "loss_d=x_entropy_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def scan(fn, start, seq):\n",
    "    res = []\n",
    "    prev = start\n",
    "    for s in seq:\n",
    "        app = fn(prev, s)\n",
    "        res.append(app)\n",
    "        prev = app\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scan(lambda prev,curr: prev+curr, 0, range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Set up training\n",
    "\n",
    "Let's now build the functions to do the forward and backward passes of our RNN. First, define our data and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inp = oh_x_rnn\n",
    "outp = oh_y_rnn\n",
    "n_input = vocab_size\n",
    "n_output = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inp.shape, outp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's the function to do a single forward pass of an RNN, for a single character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def one_char(prev, item):\n",
    "    # Previous state\n",
    "    tot_loss, pre_hidden, pre_pred, hidden, ypred = prev\n",
    "    # Current inputs and output\n",
    "    x, y = item\n",
    "    pre_hidden = np.dot(x,w_x) + np.dot(hidden,w_h)\n",
    "    hidden = act(pre_hidden)\n",
    "    pre_pred = np.dot(hidden,w_y)\n",
    "    ypred = softmax(pre_pred)\n",
    "    return (\n",
    "        # Keep track of loss so we can report it\n",
    "        tot_loss+loss(ypred, y),\n",
    "        # Used in backprop\n",
    "        pre_hidden, pre_pred, \n",
    "        # Used in next iteration\n",
    "        hidden, \n",
    "        # To provide predictions\n",
    "        ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We use scan to apply the above to a whole sequence of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_chars(n): return zip(inp[n], outp[n])\n",
    "def one_fwd(n): return scan(one_char, (0,0,0,np.zeros(n_hidden),0), get_chars(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can define the backward step. We use a loop to go through every element of the sequence. The derivatives are applying the chain rule to each step, and accumulating the gradients across the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# \"Columnify\" a vector\n",
    "def col(x): return x[:,newaxis]\n",
    "\n",
    "def one_bkwd(args, n):\n",
    "    global w_x,w_y,w_h\n",
    "\n",
    "    i=inp[n]  # 8x86\n",
    "    o=outp[n] # 8x86\n",
    "    d_pre_hidden = np.zeros(n_hidden) # 256\n",
    "    for p in reversed(range(len(i))):\n",
    "        totloss, pre_hidden, pre_pred, hidden, ypred = args[p]\n",
    "        x=i[p] # 86\n",
    "        y=o[p] # 86\n",
    "        d_pre_pred = softmax_d(pre_pred).dot(loss_d(ypred,y))  # 86\n",
    "        d_pre_hidden = (np.dot(d_pre_hidden, w_h.T) \n",
    "                        + np.dot(d_pre_pred,w_y.T)) * act_d(pre_hidden) # 256\n",
    "\n",
    "        # d(loss)/d(w_y) = d(loss)/d(pre_pred) * d(pre_pred)/d(w_y)\n",
    "        w_y -= col(hidden) * d_pre_pred * alpha\n",
    "        # d(loss)/d(w_h) = d(loss)/d(pre_hidden[p-1]) * d(pre_hidden[p-1])/d(w_h)\n",
    "        if (p>0): w_h -= args[p-1][3].dot(d_pre_hidden) * alpha\n",
    "        w_x -= col(x)*d_pre_hidden * alpha\n",
    "    return d_pre_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can set up our initial weight matrices. Note that we're not using bias at all in this example, in order to keep things simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scale=math.sqrt(2./n_input)\n",
    "w_x = normal(scale=scale, size=(n_input,n_hidden))\n",
    "w_y = normal(scale=scale, size=(n_hidden, n_output))\n",
    "w_h = np.eye(n_hidden, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our loop looks much like the theano loop in the previous section, except that we have to call the backwards step ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "overallError=0\n",
    "alpha=0.0001\n",
    "for n in range(10000):\n",
    "    res = one_fwd(n)\n",
    "    overallError+=res[-1][0]\n",
    "    deriv = one_bkwd(res, n)\n",
    "    if(n % 1000 == 999):\n",
    "        print (\"Error:{:.4f}; Gradient:{:.5f}\".format(\n",
    "                overallError/1000, np.linalg.norm(deriv)))\n",
    "        overallError=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Keras GRU\n",
    "\n",
    "Identical to the last keras rnn, but a GRU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        GRU(n_hidden, return_sequences=True, input_shape=(cs, vocab_size),\n",
    "                  activation='relu', inner_init='identity'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit(oh_x_rnn, oh_y_rnn, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_nexts_oh(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Theanu GRR\n",
    "\n",
    "### Separate weights\n",
    "\n",
    "The theano GRU looks just like the simple theano RNN, except for the use of the reset and update gates. Each of these gates requires its own hidden and input weights, so we add those to our weight matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "W_h = id_and_bias(n_hidden)\n",
    "W_x = init_wgts(n_input, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "rW_h = init_wgts(n_hidden, n_hidden)\n",
    "rW_x = wgts_and_bias(n_input, n_hidden)\n",
    "uW_h = init_wgts(n_hidden, n_hidden)\n",
    "uW_x = wgts_and_bias(n_input, n_hidden)\n",
    "w_all = list(chain.from_iterable([W_h, W_y, uW_x, rW_x]))\n",
    "w_all.extend([W_x, uW_h, rW_h])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's the definition of a gate - it's just a sigmoid applied to the addition of the dot products of the input vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gate(x, h, W_h, W_x, b_x):\n",
    "    return nnet.sigmoid(T.dot(x, W_x) + b_x + T.dot(h, W_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our step is nearly identical to before, except that we multiply our hidden state by our reset gate, and we update our hidden state based on the update gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W_h, b_h, W_y, b_y, uW_x, ub_x, rW_x, rb_x, W_x, uW_h, rW_h):\n",
    "    reset = gate(x, h, rW_h, rW_x, rb_x)\n",
    "    update = gate(x, h, uW_h, uW_x, ub_x)\n",
    "    h_new = gate(x, h * reset, W_h, W_x, b_h)\n",
    "    h = update*h + (1-update)*h_new\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Everything from here on is identical to our simple RNN in theano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp, \n",
    "                            outputs_info=[t_h0, None], non_sequences=w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "upd = upd_dict(w_all, g_all, lr)\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "err=0.0; l_rate=0.1\n",
    "for i in range(len(X)): \n",
    "    err+=fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999: \n",
    "        l_rate *= 0.95\n",
    "        print (\"Error:{:.2f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Combined weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can make the previous section simpler and faster by concatenating the hidden and input matrices and inputs together. We're not going to step through this cell by cell - you'll see it's identical to the previous section except for this concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "W = (shared(np.concatenate([np.eye(n_hidden), normal(size=(n_input, n_hidden))])\n",
    "            .astype(np.float32)), init_bias(n_hidden))\n",
    "\n",
    "rW = wgts_and_bias(n_input+n_hidden, n_hidden)\n",
    "uW = wgts_and_bias(n_input+n_hidden, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "w_all = list(chain.from_iterable([W, W_y, uW, rW]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gate(m, W, b): return nnet.sigmoid(T.dot(m, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W, b, W_y, b_y, uW, ub, rW, rb):\n",
    "    m = T.concatenate([h, x])\n",
    "    reset = gate(m, rW, rb)\n",
    "    update = gate(m, uW, ub)\n",
    "    m = T.concatenate([h*reset, x])\n",
    "    h_new = gate(m, W, b)\n",
    "    h = update*h + (1-update)*h_new\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp, \n",
    "                            outputs_info=[t_h0, None], non_sequences=w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def upd_dict(wgts, grads, lr): \n",
    "    return OrderedDict({w: w-g*lr for (w,g) in zip(wgts,grads)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "upd = upd_dict(w_all, g_all, lr)\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "err=0.0; l_rate=0.01\n",
    "for i in range(len(X)): \n",
    "    err+=fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999: \n",
    "        print (\"Error:{:.2f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
